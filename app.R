
library(shiny)
library(shinythemes)
library(meta)
library(dmetar)
library(readxl)
library(dplyr)
library(metasens)
library(metafor)
library(ggplot2)
library(ggbeeswarm)
library (MuMIn)
library(lattice)
library(bs4Dash)

library(shiny)
library(bs4Dash)



ui <- bs4DashPage(
  title = "786-MIII SMD/MD Forest Plot",
  
  # Header
  header = bs4DashNavbar(
    title = "786-MIII SMD/MD Meta-Analysis Dashboard",
    skin = "light"
  ),
  
  # Sidebar: Navigation for major sections
  sidebar = bs4DashSidebar(
    skin = "dark",
    bs4SidebarMenu(
      bs4SidebarMenuItem("Data & Options", tabName = "inputs", icon = icon("upload")),
      bs4SidebarMenuItem("General Info", tabName = "general", icon = icon("info-circle")),
      bs4SidebarMenuItem("Forest Plots", icon = icon("tree"),
                         bs4SidebarMenuSubItem("View & Options", tabName = "forest_view", icon = icon("chart-bar"))
      ),
      bs4SidebarMenuItem("Publication Bias", tabName = "pubbias", icon = icon("exclamation-triangle")),
      bs4SidebarMenuItem("Heterogeneity & Sensitivity", tabName = "hetero", icon = icon("balance-scale")),
      bs4SidebarMenuItem("Meta-Regression", tabName = "meta_reg", icon = icon("project-diagram")),
      bs4SidebarMenuItem("Other Analyses", tabName = "other", icon = icon("cogs"))
    )
  ),
  
  # Controlbar – not used in this design
  controlbar = bs4DashControlbar(),
  
  # Main body: Each tabItem represents one section of your app.
  body = bs4DashBody(
    tabItems(
      # Data & Options Tab: Contains file upload, basic parameters, and now download options.
      tabItem(
        tabName = "inputs",
        fluidRow(
          box(
            title = "Data Input & Basic Options",
            status = "primary",
            solidHeader = TRUE,
            width = 12,
            p("Upload your CSV file. The file must include these labels: 
              meanintervention, sdintervention, totalcontrol, meancontrol, sdcontrol, author. 
              For meta‑regression also include: Reg, Reg2, Reg3."),
            fileInput("fileInput", "Upload CSV File", 
                      accept = c("text/csv", "text/comma-separated-values,text/plain", ".csv")),
            tags$hr(),
            radioButtons("effectMeasure", "Effect Measure:",
                         choices = c("SMD" = "SMD", "MD" = "MD"), selected = "MD"),
            selectInput("method.smd", "Combination Method:",
                        choices = c("Hedges" = "Hedges", "Glass" = "Glass", "Cohen" = "Cohen"),
                        selected = "Hedges"),
            selectInput("method.tau", "Heterogeneity Method:",
                        choices = c("DL" = "DL", "REML" = "REML", "PM" = "PM", "EB" = "EB", "SJ" = "SJ"),
                        selected = "PM"),
            selectInput("effectModel", "Effect Model:",
                        choices = c("Random" = "RE", "Fixed" = "FE"),
                        selected = "RE"),
            selectInput("dataType", "Data Type:",
                        choices = c("SMD" = "SMD", "Odds Ratio" = "OR", "Correlation" = "r"),
                        selected = "SMD"),
            tags$hr(),
            # Global forest plot x-axis slider (for ordinary and RevMan plots)
            sliderInput("xRange", "Forest Plot X-axis Range:", 
                        min = -30, max = 30, value = c(-1, 1), step = 0.1),
            tags$hr(),
            # Plot size (for downloads)
            sliderInput("plotHeight", "Plot Height:", min = 300, max = 1000, value = 600),
            sliderInput("plotWidth", "Plot Width:", min = 300, max = 1000, value = 800)
          )
        ),
        fluidRow(
          box(
            title = "Download Options",
            status = "info",
            solidHeader = TRUE,
            width = 12,
            downloadButton("downloadForestPlot", "Download Ordinary Forest Plot as PNG"),
            downloadButton("downloadPlotRevman5", "Download Revman5 Plot as PNG"),
            downloadButton("downloadPlotJAMA", "Download JAMA Plot as PNG"),
            downloadButton("downloadPlotmeta", "Download RMA Plot as PNG"),
            downloadButton("downloadFunnelPlot", "Download Funnel Plot as PNG"),
            downloadButton("downloadBeeswarmPlot", "Download Beeswarm Plot as PNG"),
            downloadButton("downloadBubblePlot", "Download Bubble Plot as PNG"),
            downloadButton("downloadRadialPlot", "Download Radial Plot as PNG"),
            downloadButton("downloadDraperyPlot", "Download Drapery Plot as PNG"),
            downloadButton("downloadBaujatPlot", "Download Baujat Plot as PNG"),
            downloadButton("downloadInfluencePlot", "Download Influence Diagnostics Plot as PNG"),
            downloadButton("downloadEffectSizePlot", "Download Effect Size Forest Plot as PNG"),
            downloadButton("downloadI2Plot", "Download I2 Forest Plot as PNG"),
            downloadButton("downloadLMPlot", "Download Limit Meta Plot (LM) as PNG"),
            downloadButton("downloadLM2Plot", "Download Limit Meta Plot (LM2) as PNG"),
            downloadButton("downloadRainforestPlot", "Download Rainforest Plot as PNG"),
            downloadButton("downloadPcurvePlot", "Download P-curve Plot as PNG"),
            downloadButton("downloadCumForestPlot", "Download Cumulative Forest Plot as PNG"),
            downloadButton("downloadTimeTrendPlot", "Download Time-Trend Meta-Regression Plot as PNG")
          )
        )
      ),
      
      # General Info Tab
      tabItem(
        tabName = "general",
        fluidRow(
          box(
            title = "General Information",
            width = 12,
            htmlOutput("sampleCSV"),
            uiOutput("why"),
            uiOutput("forest"),
            uiOutput("model"),
            uiOutput("text")
          )
        )
      ),
      
      # Forest Plots Tab: Left column has forest plot modification options; right shows the plots.
      tabItem(
        tabName = "forest_view",
        fluidRow(
          column(width = 4,
                 box(
                   title = "Forest Plot Options",
                   status = "warning",
                   solidHeader = TRUE,
                   width = NULL,
                   selectInput("col.diamond", "Diamond Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Yellow", "Black"),
                               selected = "Black"),
                   selectInput("col.diamond.lines", "Diamond Line Color:", 
                               choices = c("Red", "Blue", "Green", "Orange",
                                           "Brown", "Pink", "Yellow", "Black"),
                               selected = "Yellow"),
                   selectInput("col.square", "Square Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Grey", "Yellow", "Black"),
                               selected = "Blue"),
                   selectInput("col.square.lines", "Square Line Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Grey", "Yellow", "Black"),
                               selected = "Black"),
                   selectInput("col.study", "Study Label Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Grey", "Yellow", "Black"),
                               selected = "Green"),
                   selectInput("col.circle", "Circle Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Grey", "Yellow", "Black"),
                               selected = "Yellow"),
                   selectInput("col.circle.lines", "Circle Line Color:", 
                               choices = c("Red", "Blue", "Green", "Purple", "Orange",
                                           "Brown", "Pink", "Grey", "Yellow", "Black"),
                               selected = "Black"),
                   checkboxInput("labstudies", "Show Study Labels", value = TRUE),
                   sliderInput("textsize", "Text Size:", min = 0.5, max = 2, value = 1, step = 0.1),
                   sliderInput("linewidth", "Line Width:", min = 0.5, max = 5, value = 1, step = 0.1),
                   textInput("label", "Left Label:", value = ""),
                   textInput("labelr", "Right Label:", value = "")
                 )
          ),
          column(width = 8,
                 box(
                   title = "Forest Plots",
                   status = "primary",
                   solidHeader = TRUE,
                   width = NULL,
                   tabBox(
                     width = NULL,
                     tabPanel("Ordinary", 
                              tags$div(
                                plotOutput("forestPlot", width = "1200px"),
                                style = "overflow-x: auto; width: 100%;"
                              )
                     ),
                     tabPanel("JAMA", plotOutput("forestPlotJAMA")),
                     tabPanel("RevMan", plotOutput("forestPlotRevman5")),
                     tabPanel("RMA", plotOutput("MA")),
                     tabPanel("Drapery", plotOutput("drapery"))
                   )
                 )
          )
        )
      ),
      
      # Publication Bias Tab: Left column shows funnel plot modification options; right displays bias outputs.
      tabItem(
        tabName = "pubbias",
        fluidRow(
          column(width = 4,
                 box(
                   title = "Funnel Plot Options",
                   status = "warning",
                   solidHeader = TRUE,
                   width = NULL,
                   sliderInput("funnelXRange", "Funnel Plot X-axis Range:", 
                               min = 0, max = 15, value = c(0.1, 5), step = 0.1),
                   checkboxInput("colorFunnel", "Color-Enhanced Funnel Plot", FALSE)
                 )
          ),
          column(width = 8,
                 box(
                   title = "Publication Bias",
                   status = "primary",
                   solidHeader = TRUE,
                   width = NULL,
                   tabBox(
                     width = NULL,
                     tabPanel("Bias Text", verbatimTextOutput("pubbias")),
                     tabPanel("Funnel Plot", plotOutput("funnelPlot")),
                     tabPanel("Trim and Fill", plotOutput("Trimfill")),
                     tabPanel("Limit Meta Curve", plotOutput("lm")),
                     tabPanel("Shrunken Limit Meta", plotOutput("lm2")),
                     tabPanel("P-Curve", plotOutput("pcurve"))
                   )
                 )
          )
        )
      ),
      tabItem(
        tabName = "hetero",
        fluidRow(
          box(
            title = "Heterogeneity & Sensitivity",
            width = 12,
            tabBox(
              width = 12,
              tabPanel("Heterogeneity Text", verbatimTextOutput("hetro")),
              tabPanel("Heterogeneity (Cochrane)", verbatimTextOutput("hetro_dynamic_cochrane")),
              tabPanel("Heterogeneity (NEJM)", verbatimTextOutput("hetro_dynamic_nejm")),
              tabPanel("Heterogeneity (Lancet)", verbatimTextOutput("hetro_dynamic_lancet")),
              tabPanel("Heterogeneity (Plain Language)", verbatimTextOutput("hetro_dynamic_plain")),
              tabPanel("Baujat Plot", plotOutput("Baujatplot")),
              tabPanel("Influence Diagnostics", plotOutput("Influence")),
              tabPanel("Effect Size Plot", plotOutput("effectsize")),
              tabPanel("I2 Forest Plot", plotOutput("I2")),
              tabPanel("Radial Plot", plotOutput("radial")),
              tabPanel("Leave-One-Out Analysis", verbatimTextOutput("leaveOneOutText"))
            )
          )
        )
      ),
      
      
      # Meta-Regression Tab
      tabItem(
        tabName = "meta_reg",
        fluidRow(
          box(
            title = "Meta-Regression",
            width = 12,
            tabBox(
              width = 12,
              tabPanel("Single Moderator Text", verbatimTextOutput("metareg")),
              tabPanel("Two Moderator Regression", verbatimTextOutput("singleMetaregText")),
              tabPanel("Three Moderator Regression", verbatimTextOutput("threeMetaregText")),
              tabPanel("Bubble Plot", plotOutput("BubblePlot")),
              tabPanel("Selector Bubble Plot", 
                       fluidRow(
                         column(4, selectInput("selectedModerator", "Select Moderator:", 
                                               choices = c("Reg", "Reg2", "Reg3"), selected = "Reg")),
                         column(8, plotOutput("singleBubblePlot"))
                       )
              ),
              tabPanel("Multiple Meta-Regression Analytics", plotOutput("mmreg"))
            )
          )
        )
      ),
      
      # Other Analyses Tab (Network Meta-Analysis removed)
      tabItem(
        tabName = "other",
        fluidRow(
          box(
            title = "Other Analyses",
            width = 12,
            tabBox(
              width = 12,
              tabPanel("Cumulative Meta-Analysis Text", verbatimTextOutput("cumMetaText")),
              tabPanel("Cumulative Forest Plot", plotOutput("cumForestPlot")),
              tabPanel("Time-Trend Meta-Regression", verbatimTextOutput("timeTrendText")),
              tabPanel("Bayesian Meta-Analysis", verbatimTextOutput("bayesianMetaText"))
            )
          )
        )
      )
    )
  ),
  
  # Footer
  footer = bs4DashFooter("Copyright © 2025 Your Name or Organization")
)





server <- function(input, output, session) {
  
  # Reactive expression to read CSV file
  dataInput <- reactive({
    req(input$fileInput)
    read.csv(input$fileInput$datapath)
  })
  
  output$why <- renderUI({
    HTML("
     <p>'He has encouraged us to use our brains and to ponder upon His creation and to search for new roads of human progress and innovation through research and reflection` (Mirza Masroor Ahmad) </p>
    <p> 
    <p></p>
    I would like to acknowledge the Ahmadiyya Muslim Research Association, Luciano Candilio, Malik Takreem Ahmad, Niraj Kumar, Jonathan Bray,Reubeen Ahmad and Prof Rui Providencia</p>
  
    <p>Najia Ahmad, Student</p>
<p>Tamar Schreiber, BSc, UCL</p>
<p>Malik Takreem Ahmad, MBBS, King’s College London</p>
<p>Reubeen Ahmad, MBBS, Brighton and Sussex medical school</p>
<p>Olivia Frost, BSc, UCL, St George’s Medical School</p>
<p>Lily Snell, MBBS, UCL Medical School</p>
<p>Nishika Bhatt, MBBS, UCL Medical School</p>
<p>Bilaal Dar, MBBS, King’s College London</p>
<p>Zahid Khan, MBBS, MRCP, MSc Cardiology, MSc Medical and Health Education, Bart’s Heart Centre, London & University of South Wales, UK</p>
<p>Honey Panchal, MBBS BSc, University College London</p>
<p>Tayyibah Patel, MBBS BSc, UCL</p>
<p>Shayan Shaikh, MBBS BSc, UCL</p>
<p>Sophie E Thompson, MBChB, University Hospitals Birmingham NHS Foundation Trust</p>
<p>Gurkiran Kaur Sandhar, MBBS, UCL Medical School</p>
<p>Girishkumar Sivakumar, MBBS BSc, UCL Medical School</p>
<p>Shubkhez Azeem Bajwa, MBBS BSc, St George’s Medical School</p>
<p>Hannah Glatzel, MBChB, BSc, Hutt Hospital, Wellington, NZ</p>
<p>Mahmood Ahmad, MBBS, Royal Free Hospital</p>
<p>YuZhi Phuah, MBBS, University College London</p>
<p>Niraj S Kumar, PhD, Department of Cardiovascular Sciences, University of Leicester + National Medical Research Association, London, UK</p>
<p>Hamaad Muin Ahmad, MUDr, Croydon University Hospital</p>
<p>Zain M Ahmad, Student</p>
<p>Zaki Ahmad, Student</p>
<p>Gaayen Ravii Sahgal, MBBS, King’s College London</p>
<p>Cynthia Ng, MBBS, BSc, UCL</p>
<p>Safa Kindawi, MBBS, iBSc, UCL Medical School</p>
<p>Kieran Williams, MBBS, iBSc, UCL Medical School</p>
<p>Osarumwense Ogbeide, MBBS, UCL Medical School</p>
<p>Shahzad Hashmi, MBBS iBSC, Imperial College London</p>
<p>Max Aboutorabi, MBBS iBSC, UCL Medical School</p>
<p>Lakshmi Kowdley Hemanth, MBBS iBSc Student, UCL Medical School</p>
<p>Kirshu Suvendiran, MBBS, UCL Medical School</p>
<p>Amelia Snook, MBBS BSc, UCL Medical School</p>
<p>Eesha Dev, MBBS, iBSc, UCL Medical School</p>
<p>Ahmed Salih, MBBS BSc, Imperial College London</p>
<p>Ameera Milhan, MBBS, iBSc, UCL Medical School</p>
<p>Maryam Imran, MBBS, iBSc, UCL Medical School</p>
<p>Buvani Punniyakotty, MBBCh BAO, Trinity College Dublin</p>
<p>Erica Sugita, MBChB, Warwick Medical School</p>
<p>Majed Sheikh, MD, University of Pecs Medical School</p>
<p>Talha Raza, MBBS, iBSc, UCL Medical School</p>
<p>Tony-Harshan Linton-Jude, MBBS, iBSc, UCL Medical School</p>
<p>Ruhi Satia, MBBS iBSc, UCL Medical School</p>
<p>Michelle Husna Esmati, MBBS iBSc, St George’s Medical School, Imperial College London</p>
<p>Alvin Jaison, MBBS, UCL Medical School</p>
<p>Sanjali Anil Chu Ahuja, MBBS, MSc, Barts & the London School of Medicine & Dentistry, Queen Mary University of London</p>
<p>Rauhaan Tahir, MBBS, St George’s University</p>
<p>Malak Al Qaimari, MD, University of Szeged</p>
<p>Jonathan Kow, MBBS BSc Student, Imperial College London</p>
    ")
  })
  
  output$mtext <- renderUI({
    HTML("
    <h2>Diving into Meta-Regression in Meta-Analysis</h2>
    <p>Meta-regression is like the detective work of meta-analysis. Instead of just summarizing study results, you explore what factors might influence those results. It’s your chance to dig deeper and uncover the mysteries behind the data. Let’s dive into the tools and plots that help us solve these puzzles.</p>

    <h3>Meta-Regression Text Results</h3>
    <p>The meta-regression text results provide detailed statistics and insights about how different variables (called moderators) impact the overall effect size. Think of it as your case file, revealing how each clue fits into the bigger picture.</p>
    <p>Here are some of the key components you might encounter:</p>
    <ul>
      <li><strong>Regression Coefficients:</strong> These numbers show how much the outcome changes with each unit change in the moderator variable. It’s like finding out that for every extra hour of studying, your test scores improve by a certain number of points. For example, a coefficient of 0.5 suggests that each additional study hour increases your test score by half a point.</li>
      <li><strong>Confidence Intervals:</strong> These intervals give you a range where the true effect of the moderator likely falls. If they don’t include zero, your moderator is likely having a significant impact. It's like knowing that there's a 95% chance your increased study hours will boost your scores within a specific range. For instance, a confidence interval of [0.2, 0.8] for the study hours means you can be reasonably sure the effect lies somewhere between those values.</li>
      <li><strong>p-Values:</strong> These tell you whether the effect of your moderator is statistically significant. A low p-value (typically less than 0.05) suggests your moderator is more likely to be a real influencer rather than a random fluke. Think of it as the evidence that makes your case stronger. If your p-value is 0.03, it's like having a solid piece of evidence in your detective case.</li>
      <li><strong>R² (R-squared):</strong> This statistic shows how much of the variation in study results can be explained by the moderators. Higher R² values mean your moderators are doing a good job explaining differences. It’s like saying, 'This study habit explains 80% of why students get different scores.' For example, an R² of 0.75 means that 75% of the variability in test scores can be accounted for by your study habits.</li>
    </ul>
    <p>These text results are crucial as they help you understand the role of different moderators in influencing the effect size. It’s your first step in uncovering the underlying patterns in your meta-analysis data.</p>

    <h3>Meta-Regression Bubble Plot</h3>
    <p>A bubble plot is a visual way to show the relationship between the effect sizes and a moderator variable. Imagine a scatter plot where the size of each bubble represents the weight of the study. It’s like plotting your friends’ movie ratings against their time spent watching trailers, with bigger bubbles for the more vocal friends.</p>
    <p>Here’s how to read a bubble plot:</p>
    <ul>
      <li><strong>Effect Sizes:</strong> The position of each bubble on the y-axis represents the effect size from each study. Higher bubbles indicate larger effect sizes, suggesting stronger effects.</li>
      <li><strong>Moderator Variable:</strong> The x-axis shows the values of your moderator variable. For instance, if you're examining study hours, the x-axis would show the range of hours spent studying.</li>
      <li><strong>Bubble Size:</strong> The size of each bubble reflects the weight or importance of the study, usually based on sample size. Larger bubbles mean the study has more influence on the overall results.</li>
      <li><strong>Trends and Patterns:</strong> Look for patterns or trends in the bubbles. For example, if the bubbles tend to rise as you move right along the x-axis, it suggests a positive relationship between the moderator and effect size.</li>
    </ul>
    <p>The bubble plot helps you see if there’s a trend or pattern. For example, you might notice that as the number of trailers watched increases, the movie ratings tend to get higher. This visual tool is handy for spotting trends that might not be obvious from the numbers alone.</p>

    <h3>Multiple Meta-Regression Text Results (Risk Ratio)</h3>
    <p>When you’re dealing with multiple moderators, things can get a bit more complex. The text results for multiple meta-regression provide insights into how several variables together influence the effect size. It’s like juggling multiple clues in your detective case, each adding a piece to the puzzle.</p>
    <p>Key components include:</p>
    <ul>
      <li><strong>Interaction Terms:</strong> These terms show how the effect of one moderator might depend on the level of another moderator. It's like discovering that your study time’s impact on scores also depends on how much sleep you get. For instance, the effect of study hours on test scores might be stronger for students who get 8 hours of sleep compared to those who get only 5 hours.</li>
      <li><strong>Overall Model Fit:</strong> This tells you how well your combined moderators explain the variation in the effect sizes. A good fit means you’re on the right track in solving the mystery. You’ll look at statistics like the F-test to determine if your model significantly improves the prediction of effect sizes.</li>
      <li><strong>Adjusted R²:</strong> Similar to R² but adjusted for the number of moderators in your model. It’s a more accurate reflection of how well your model explains the data, considering you’ve added multiple clues. An adjusted R² of 0.70, for example, suggests that 70% of the variability is explained by your combined moderators, accounting for the complexity of the model.</li>
      <li><strong>Coefficients for Each Moderator:</strong> Each moderator gets its own coefficient, confidence interval, and p-value, helping you understand their individual contributions. It's like having detailed evidence for each suspect in your case, showing who contributes what to the overall story.</li>
    </ul>
    <p>These results are crucial for understanding the combined impact of multiple factors on the effect size, helping you build a more comprehensive picture of the research landscape.</p>

    <h3>Multiple Meta-Regression Performance Analytic</h3>
    <p>This involves using performance analytics to evaluate and visualize the effectiveness of your multiple meta-regression model. It’s like getting a performance review for your detective skills, showing you how well you’ve pieced together the clues.</p>
    <p>Key tools include:</p>
    <ul>
      <li><strong>Chart.Correlation:</strong> This chart shows the correlation between your moderators and the effect sizes, helping you see which variables are closely related. It's like figuring out which study habits are most strongly linked to exam success. You’ll see a matrix of correlation coefficients that indicate the strength and direction of relationships.</li>
      <li><strong>Model Selection Criteria:</strong> Tools like AIC (Akaike Information Criterion) help you compare different models to see which one fits the data best. It’s like comparing different detective strategies to see which one solves the case most effectively. Lower AIC values suggest a better-fitting model. You'll often use criteria like AICc (corrected AIC) for smaller sample sizes.</li>
      <li><strong>Residual Plots:</strong> These plots show the residuals (differences between observed and predicted values) to check for patterns. It’s like checking your work for any inconsistencies or errors. A good model will have residuals randomly scattered around zero, indicating no obvious pattern or bias.</li>
      <li><strong>Goodness-of-Fit Tests:</strong> These tests, like the Chi-square goodness-of-fit test, help determine how well your model matches the observed data. It’s another way to ensure your detective work is accurate and reliable.</li>
    </ul>
    <p>Using these performance analytics, you can refine your meta-regression model to ensure it provides the most accurate and insightful conclusions. It’s your final check to make sure your detective work is spot on.</p>

    <p>By using these tools and methods, you can uncover the underlying factors that influence study results, ensuring a deeper and more nuanced understanding of the research data. Just like a good detective, you'll be able to see beyond the surface and understand the full story.</p>
  ")
  })
  
  output$pubtext <- renderUI({
    HTML("
    <h2>Exploring Publication Bias in Meta-Analysis</h2>
    <p>When conducting a meta-analysis, understanding publication bias is crucial. It’s like trying to get an accurate picture of your friend’s favorite movies but only hearing about the blockbuster hits. Let's dive into some tools and plots that help uncover the hidden gems (or biases) in the research world.</p>

    <h3>Publication Bias Text Results</h3>
    <p>The publication bias text results provide a comprehensive summary of key statistics and indicators that reveal the presence and extent of publication bias in your meta-analysis. Think of it as the critical review section where all the underlying biases and potential issues are laid bare.</p>
    <p>Here are some of the key components you might encounter in the text results:</p>
    <ul>
      <li><strong>Egger’s Test:</strong> This statistical test checks for asymmetry in the funnel plot. A significant result suggests that smaller studies may be missing, likely due to publication bias. It's like finding out that the only movies your friends didn’t mention are the ones they didn’t like much.</li>
      <li><strong>Begg’s Test:</strong> Another test for funnel plot asymmetry, Begg’s test is less sensitive than Egger’s but still useful. It’s like getting a second opinion on whether there's a skew in the studies being reported.</li>
      <li><strong>Trim and Fill Analysis:</strong> This method not only identifies but also corrects for funnel plot asymmetry by 'trimming' the asymmetric studies and 'filling' in the gaps with estimated missing studies. The adjusted results give a more accurate picture, akin to getting a more balanced list of movies, including those not initially mentioned.</li>
      <li><strong>Fail-safe N:</strong> This statistic tells you how many non-significant studies would be needed to nullify the meta-analysis results. If the number is high, your findings are robust. It’s like knowing how many bad reviews would be needed to make you doubt that a blockbuster is actually good.</li>
    </ul>
    <p>These text results are crucial as they help you understand whether the conclusions drawn from your meta-analysis are likely to be influenced by the selective publication of studies. It’s your first step in ensuring that you have a complete and unbiased picture of the research landscape.</p>

    <h3>Visualization Tools for Publication Bias</h3>
    <p>Visual tools provide a more intuitive understanding of publication bias. Let’s explore some of these plots that help you see the bigger picture:</p>

    <h3>Publication Bias Funnel Plot</h3>
    <p>Imagine a funnel plot as a scatterplot where each study is a dot. If there’s no bias, the dots will form a symmetrical funnel shape. If the plot looks lopsided, it might be hinting that some studies are missing—like your friends only sharing their favorite blockbuster movies and skipping the indie flicks. This plot is your first visual check for bias, helping you spot any obvious imbalances at a glance.</p>
    <p>The idea is simple: more precise studies (usually larger ones) should cluster around the true effect size, while smaller, less precise studies should scatter more widely at the bottom of the funnel. If studies are missing—often those with non-significant results—you’ll see an asymmetry, like a funnel missing one side. This asymmetry is a red flag for publication bias.</p>

    <h3>Publication Bias Trim and Fill</h3>
    <p>The trim and fill method is like adding missing pieces to a jigsaw puzzle. It identifies and estimates the number of missing studies to adjust the overall effect size. This way, you get a more complete picture, accounting for the studies that didn’t make it to publication. Imagine your friend tells you only about the exciting scenes from a movie, and you have to guess what happened in the dull parts they skipped. Trim and fill helps by estimating what those skipped parts might look like and adding them back in to give a fuller story.</p>
    <p>In practical terms, the method trims the asymmetric studies that are causing the funnel to be uneven and then fills in the gap with hypothetical studies that balance the funnel. The adjusted meta-analysis provides a more honest estimate of the effect size, considering the bias. It’s like getting a sneak peek at the deleted scenes that didn’t make it to the final cut.</p>

    <h3>Publication Bias Limit Meta-Analysis Curve</h3>
    <p>This technique plots the effect sizes and their standard errors to assess bias. The curve helps to identify any systematic bias in the studies. It's like plotting all your friends’ movie reviews to see if there’s a trend in their preferences. You might notice that they always rate action movies higher, suggesting a bias in their ratings.</p>
    <p>The limit meta-analysis curve provides a visual way to understand how the effect sizes change with varying levels of precision. If the curve indicates that more precise studies show a different effect than less precise ones, it’s a clue that publication bias or other small-study effects might be at play. It's akin to seeing if all the high-budget blockbusters get rave reviews while the low-budget films are overlooked, revealing a bias in the preferences or availability of reviews.</p>

    <h3>Advanced Methods for Detecting Publication Bias</h3>
    <p>For those who want to delve even deeper into the analysis of publication bias, here are some advanced methods that offer a more nuanced look:</p>

    <h3>Publication Bias Limit Meta-Analysis Curve and Shrunken</h3>
    <p>Similar to the regular limit meta-analysis curve but with a twist: it adjusts or 'shrinks' the effect sizes to correct for the bias. Think of it as getting your friends to reassess their movie ratings after considering the hidden gems they initially overlooked. This method fine-tunes the analysis to account for the missing studies, giving a more balanced view of the data.</p>
    <p>By shrinking the effect sizes, this method reduces the inflation caused by publication bias. It’s like asking your friends to rate movies not just based on the initial hype but also considering those underrated films they might have ignored. The adjusted curve then provides a more accurate reflection of the true effect size, free from the skew caused by missing studies.</p>

    <h3>Publication Bias P-Curve</h3>
    <p>The P-curve analyzes the distribution of p-values from the studies to determine if there’s evidence of p-hacking or selective reporting. It’s like checking if your friends are only telling you about movies they rated highly, skewing your perception of what’s actually good.</p>
    <p>By looking at the distribution of statistically significant p-values, the P-curve helps detect if there’s a suspiciously high number of just-significant results, suggesting that studies with non-significant results might be underreported. It’s like realizing that all your friends’ favorite movies have just the right amount of action or drama to barely make it interesting, making you wonder if they’re only remembering the highlights.</p>
    <p>The P-curve provides insights into the credibility of the findings by showing if the distribution of significant p-values matches what would be expected if the true effect is real and not just a result of selective reporting. It’s a tool to ensure that what you see is genuinely reflective of the entire spectrum of research, not just the cherry-picked highlights.</p>
    
    <p>Each of these tools and plots helps you uncover the hidden biases in your meta-analysis, ensuring you get a balanced view of all the evidence. They’re your statistical magnifying glass, helping you spot where the research picture might be a bit distorted. Just like making sure you hear about all the movies—blockbusters and indie films alike—these methods help ensure your meta-analysis captures the full story, warts and all.</p>
  ")
  })
  
  output$htext <- renderUI({
    HTML("
    <h2>Exploring Heterogeneity in Meta-Analysis</h2>
    <p>When conducting a meta-analysis, understanding heterogeneity is crucial. It's like figuring out why your group of friends all have different tastes in movies. Let's dive into some tools and plots that help us get to the bottom of this variability.</p>

    <h3>Heterogeneity Text Results</h3>
    <p>This is your basic report card. It gives you key stats like I² and tau², telling you how much the study results vary and how confident you can be in the overall findings. Think of it as the vital signs check before you dive deeper.</p>

    <h3>Heterogeneity Baujat Plot</h3>
    <p>Imagine a Baujat plot as a spotlight on the troublemakers. It shows which studies contribute most to the heterogeneity and influence the meta-analysis result. If one study is causing all the drama, this plot will point it out.</p>

    <h3>Heterogeneity Influence Diagnostics</h3>
    <p>These diagnostics are like your group therapy sessions, revealing how each study affects the overall meta-analysis. You can see which studies are steady contributors and which ones might be skewing the results. It's all about understanding individual impacts.</p>

    <h3>Heterogeneity Effect Size Forest Plot</h3>
    <p>This classic plot shows the effect sizes of all studies in a meta-analysis. It's like lining up all your friends and seeing how their movie preferences vary. Each line represents a study, showing its effect size and confidence interval, with the overall effect at the bottom.</p>

    <h3>Heterogeneity I² Forest Plot</h3>
    <p>This plot is similar to the effect size forest plot but with a twist. It includes I² values, indicating the percentage of variation across studies that's due to heterogeneity rather than chance. Think of it as adding a layer of analysis to understand how different everyone's tastes really are.</p>

    <h3>Heterogeneity L'Abbé Plot</h3>
    <p>The L'Abbé plot is like a scatterplot where you compare the control group's event rate to the treatment group's event rate for each study. It helps visualize the consistency of treatment effects across studies. It's a great way to spot patterns or outliers.</p>

    <h3>Heterogeneity Radial Plot</h3>
    <p>A radial plot is your meta-analysis compass. It plots the standardized effect sizes against precision, helping to identify outliers and influential studies. It's particularly useful for spotting those studies that might be throwing off your overall results.</p>

    <p>Each of these tools and plots helps you dissect the variability in your meta-analysis, ensuring you understand why studies differ and how that affects your overall findings. Think of them as the detective tools in your statistical toolkit, each one helping to piece together the puzzle of heterogeneity.</p>
    ")
  })
  
  
  output$text <- renderUI({
    HTML("
    <h2>A Glimpse Into the World of Meta-Analysis</h2>
    <p>
    You can use the text output to write our results using either of these GPT
    https://chatgpt.com/g/g-k7FryNboI-786miii-meta-results-writer
    https://chatgpt.com/g/g-GBxPpwHBY-risk-ratio-results-writer
    
    Also you can do risk of bias with these tools
    
    
    Imagine each study in a meta-analysis is like a guest at a dinner party; they all bring something to the table, but not all of their contributions weigh equally. Let's decode what they're serving up and why some of them might get the bigger slice of cake (or, in our case, a bigger say in the results).</p>

    <h3>Study-Specific Data:</h3>
    <ul>
      <li><strong>Risk Ratios (RR) and Confidence Intervals:</strong> Each study provides a Risk Ratio, telling us how much the odds of an event increase (or decrease) with a particular intervention. The confidence intervals wrap this ratio in a cozy blanket of 'we're pretty sure it's around this value,' giving a range that says, 'Look here, but with a grain of salt.'</li>
      <li><strong>Weights:</strong> Not all studies are created equal. Those with more precise estimates (tight confidence intervals) often carry more weight in the analysis. It’s a bit like in group projects; the person who does the most work often has the most say.</li>
    </ul>

    <h3>Aggregated Insights:</h3>
    <p>After all studies chime in, we get the big picture:</p>
    <ul>
      <li><strong>Total Number of Studies and Observations:</strong> More studies and observations typically mean more robust conclusions. Think of it as gathering a larger consensus from a crowd—more voices can provide a clearer answer.</li>
      <li><strong>Overall Effect:</strong> This is where we see what all the studies, when considered together, suggest about the intervention. Is it effective? Is it not? This pooled estimate, represented by a snazzy diamond in many plots, gives us the consensus of the collected research.</li>
    </ul>

    <h3>Dealing with Differences - Heterogeneity:</h3>
    <p>Sometimes, studies don’t all sing the same tune, and this is where heterogeneity metrics come into play:</p>
    <ul>
      <li><strong>Tau² and I²:</strong> These are the gossipmongers of meta-analysis. Tau² whispers about the actual differences in effect sizes behind the scenes, while I² tells us what percentage of these differences is due to genuine disagreement rather than just random noise.</li>
      <li><strong>Q-test:</strong> This is like asking, 'Are you all really disagreeing that much, or is it just a misunderstanding?' A significant result means, yes, they truly don’t see eye to eye.</li>
    </ul>

    <h3>Methodological Fine Print:</h3>
    <p>The methods used can affect the final story told by the meta-analysis. Whether it’s the inverse variance method or another statistical approach, each has its own way of handling the data—kind of like different chefs might treat the same ingredients differently to make a dish uniquely their own.</p>

    <p>In essence, a meta-analysis tries to put together a coherent narrative from diverse research studies, assessing both their individual contributions and how they combine to answer a broader question. It’s a bit like creating a mosaic where every piece matters; only here, the pieces are studies, and the picture they form helps guide medical decisions.</p>
    ")
  })
  
  
  output$model <- renderUI({
    HTML("
   
         <h2>Choosing the Right Tools for Meta-Analysis: SMD/MD</h2>
           <p>Just like choosing the appropriate unit of measurement for temperature, selecting between Mean Difference (MD) and Standardized Mean Difference (SMD) is crucial in meta-analysis. Here’s a breakdown of some key decisions you may face when analyzing continuous data:</p>
           
           <h3>Effect Measure: MD vs. SMD</h3>
           <p>If all studies report outcomes on the same scale, <strong>Mean Difference (MD)</strong> offers a direct interpretation of the difference between intervention and control groups. However, when studies use different measurement scales, the <strong>Standardized Mean Difference (SMD)</strong> is preferred because it expresses the effect size in units of standard deviation, making the results comparable across studies.</p>
           <ul>
           <li><strong>Mean Difference (MD):</strong> Represents the absolute difference between group means. It’s intuitive and directly interpretable when outcomes are measured on the same scale.</li>
           <li><strong>Standardized Mean Difference (SMD):</strong> Converts the difference into a unitless measure by dividing by the standard deviation, which is ideal when different studies use different scales.</li>
           </ul>
           
           <h3>Combination Method</h3>
           <p>Different methods exist to pool effect sizes from individual studies:</p>
           <ul>
           <li><strong>Inverse Variance Method:</strong> Weighs studies by the inverse of the variance, giving more weight to more precise studies.</li>
           <li><strong>Hedges’ g:</strong> A commonly used variant of SMD that adjusts for small sample bias.</li>
           <li><strong>Cohen’s d:</strong> Another popular measure of standardized effect size, though it may be biased in small samples.</li>
           </ul>
           
           <h3>Heterogeneity Method</h3>
           <p>Since study results rarely align perfectly, several methods are available to estimate and account for heterogeneity:</p>
           <ul>
           <li><strong>DerSimonian-Laird (DL):</strong> A classic method that is straightforward but may underestimate heterogeneity with small sample sizes.</li>
           <li><strong>Restricted Maximum Likelihood (REML):</strong> Provides a more robust estimate of between-study variance.</li>
           <li><strong>Paule-Mandel (PM):</strong> An alternative estimator that sometimes offers a better fit.</li>
           <li><strong>Empirical Bayes (EB) and Sidik-Jonkman (SJ):</strong> Additional methods that incorporate prior information or adjust for small-sample effects.</li>
           </ul>
           
           <h3>Effect Model: Random vs. Fixed Effects</h3>
           <p>The choice between these models determines how the overall effect is estimated:</p>
           <ul>
           <li><strong>Random Effects (RE):</strong> Assumes the true effect size varies between studies and accounts for this heterogeneity.</li>
           <li><strong>Fixed Effects (FE):</strong> Assumes that all studies share the same underlying effect size, appropriate when studies are very similar.</li>
           </ul>
           <p>Each decision—from the choice of MD versus SMD, through the combination and heterogeneity methods, to the effect model—can significantly influence your conclusions. Choosing the right options is like picking the perfect gear before a dive: it ensures that you explore the depths of your data accurately and come back with true insights.</p>
           ")
  })
  
  
  
  output$forest <- renderUI({
    HTML("
    <h2>Introduction to Forest Plots</h2>
    <p>In the creation of the heavens and the earth and in the alternation of the night and the day there are indeed Signs for men of understanding(The Holy Quran)</p>
    <p>Forest plots, also humorously dubbed 'blobbograms', are a staple in meta-analysis, essentially serving as a high-level overview of multiple studies on a single question. These plots provide a clear visual representation of individual study results alongside a collective summary, making them crucial in medical research where detail and precision are paramount.</p>
    <ul>
      <li><strong>Study Labels:</strong> Displayed on the left, each study is listed by the primary author's name and the year of publication, organizing the research lineage neatly.</li>
      <li><strong>Effect Sizes:</strong> Central to the plot, these figures (like odds ratios or risk ratios) quantify the impact of interventions. For instance, an odds ratio above 1 might quietly hint at a beneficial effect of a treatment.</li>
      <li><strong>Confidence Intervals:</strong> These horizontal lines suggest the reliability of effect sizes. If they shy away from the line of no effect, the results are statistically significant, whispering 'there's something here worth considering.'</li>
      <li><strong>Weights:</strong> Not all studies are created equal in a forest plot. Those with larger sample sizes and precise estimates carry more weight, their influence visibly larger on the plot.</li>
      <li><strong>Diamond:</strong> This figure represents the pooled estimate of effect sizes from all included studies. Its position and width offer a quick visual cue about the overall results, akin to reading the room in a glance.</li>
    </ul>
    <h2>How to Read a Forest Plot</h2>
    <p>Interpreting a forest plot involves a few steps akin to reading a complex watch:</p>
    <ul>
      <li><strong>Locate the Line of No Effect:</strong> This line serves as a benchmark for assessing the effectiveness of an intervention. It's a sober reminder of what neutrality looks like in numerical terms.</li>
      <li><strong>Assess Individual Study Results:</strong> Examine where the confidence intervals land in relation to this line. Those that don’t cross it are subtly asserting their statistical significance.</li>
      <li><strong>Evaluate the Diamond:</strong> The position and spread of the diamond synthesize the overall data, providing a broad perspective at a glance. If it avoids the line of no effect, the combined data suggests a clear direction.</li>
      <li><strong>Consider the Weights:</strong> The size of the squares reflects the influence of each study, a gentle nod to the idea that more data typically provides clearer answers.</li>
    </ul>
    <h2>Statistical Considerations in Forest Plots</h2>
    <p>Delving into the statistics of forest plots unveils further depth:</p>
    <ul>
      <li><strong>Heterogeneity:</strong> This metric measures the variability among study outcomes, highlighting whether it’s prudent to combine these studies at all. High heterogeneity can be a quiet murmur for caution, suggesting differences that might need further exploration.</li>
      <li><strong>Random vs. Fixed Effects Models:</strong> Choosing between these models is like deciding whether to assume uniformity or embrace diversity among study results. Each model brings its own perspective to the analysis, affecting the interpretation of the pooled estimate.</li>
    </ul>
   
     <h2>Choosing Your Forest Plot Adventure</h2>
    <p>Like picking your outfit for the first day of a clinical rotation, choosing the right tool for your forest plot can make a big difference. Each tool or style has its own 'personality' and perks, depending on how fancy you need to get with your data.</p>
    
    <h3>RevMan</h3>
    <p>Think of RevMan as the reliable, no-nonsense type. Developed by the Cochrane Collaboration, it’s the go-to for many healthcare reviews. Its plots are like well-organized notes—clear, straightforward, and exactly what you need for a standard look that complies with Cochrane's methodical standards. It's user-friendly too, perfect for those still getting their feet wet in meta-analysis.</p>
    
    <h3>Forest from Meta in R</h3>
    <p>The `forest()` function in R’s `meta` package is the artsy friend who lets you customize everything. Need to tweak the layout or add some subgroup flair? No problem. It's ideal for those who enjoy tailoring their visuals to the nth degree or for when your data needs to show off a bit more complexity.</p>
    
    <h3>JAMA-Style Forest Plots</h3>
    <p>If your forest plot needs to dress to impress, JAMA-style is like the sharp suit of graph styles. Used for papers in the Journal of the American Medical Association, these plots are sleek and professional with just enough graphical sophistication to make your data look its best in high-stakes journal submissions.</p>
    
    <h3>RMA Forest Plots from Metafor</h3>
    <p>For those who relish diving deep into the statistical nitty-gritty, the `metafor` package offers RMA forest plots. They’re like the Swiss Army knife for data analysis—robust, precise, and ready to handle complex models and sensitivity checks with ease. It’s the choice for the data geeks who speak fluent stats.</p>
    
    <p>In the end, picking the right forest plot tool is about matching your project’s needs with the right features—kind of like choosing whether to study with flashcards, app quizzes, or the good old-fashioned textbook. Some tools are better for a quick review, while others will help you explore every detail, depending on the audience and your flair for drama (or data).</p>
    <h2>Understanding Drapery Plots in Meta-Analysis</h2>
    <p>Drapery plots, while less commonly discussed than their cousin the forest plot, offer a unique way to visualize data in meta-analyses. Imagine them as the sophisticated drapes in a grand theatre—they not only look good but also provide a deeper layer of understanding to what's on stage (your data).</p>

    <p>So, what exactly is a drapery plot? Think of it as a forest plot with a flair for the dramatic. While forest plots focus on showing the effect sizes and confidence intervals of individual studies, drapery plots add an extra dimension—literally. They visualize the probability densities or likelihood of the effect sizes across studies. This means you not only see where the effects might lie but also how they spread and cluster, giving you a sense of the density of data points at different effect sizes.</p>

    <p>Why use drapery plots? They're particularly useful when you want to illustrate the precision and distribution of study results in a visually impactful way. In medical research, where understanding the variability and certainty of study outcomes can be as crucial as the outcomes themselves, drapery plots provide a clear picture of where the bulk of evidence lies and how robust it is. They help in spotting trends, assessing the weight of evidence, and identifying outliers that might skew your meta-analytical conclusions.</p>

    <p>In essence, a drapery plot doesn't just tell you what the effect might be; it shows you how confident you can be about the range of possible effects. It's like getting a peek behind the curtain, seeing not only the performers but also the stagehands—everything that supports and affects the performance (study results).</p>

    ")
  })
  
  
  
  
  library(metafor)  # For meta-analysis via rma and forest plots
  library(dmetar)   # For multimodel inference
  library(dplyr)    # For data manipulation
  library(ggplot2)  # For advanced plotting
  
  library(magrittr)  # For the pipe operator
  library(metafor)   # For meta-analysis and forest plot
  library(dplyr)     # For data manipulation
  
  output$MA <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Calculate effect sizes and variances using escalc function from metafor
    dat <- escalc(measure = input$effectMeasure,  # "MD" for Mean Difference or "SMD" for Standardized Mean Difference
                  m1i = dat$meanintervention,
                  sd1i = dat$sdintervention,
                  n1i = dat$totalintervention,
                  m2i = dat$meancontrol,
                  sd2i = dat$sdcontrol,
                  n2i = dat$totalcontrol,
                  data = dat,
                  slab = dat$author)
    
    # Fit the random-effects model using rma
    rma.model <- rma(yi = yi, vi = vi, data = dat, method = "REML")
    
    # Check if the moderators are present in the dataset
    if(all(c("Reg", "Reg2", "Reg3") %in% names(dat))) {
      # Fit the random-effects model with moderators
      rma.model.with.mods <- rma(yi = yi, vi = vi, mods = ~ Reg + Reg2 + Reg3, data = dat, method = "REML")
      
      # Plot the results from the random-effects model with moderators
      forest(rma.model.with.mods, main = "Forest Plot of RMA Model with Moderators", 
             xlab = ifelse(input$effectMeasure == "MD", "Mean Difference", "Standardized Mean Difference"), 
             slab = paste(dat$author))
      
    } else {
      # If moderators are not available, use the basic model for plotting
      forest(rma.model, main = "Forest Plot", 
             xlab = ifelse(input$effectMeasure == "MD", "Mean Difference", "Standardized Mean Difference"), 
             slab = paste(dat$author))
    }
  })
  
  
  library(metafor)  # For meta-analysis via rma and forest plots
  library(dmetar)   # For multimodel inference
  library(dplyr)    # For data manipulation
  library(ggplot2)  # For advanced plotting
  
  library(magrittr)  # For the pipe operator
  library(metafor)   # For meta-analysis and forest plot
  library(dplyr)     # For data manipulation
  
  output$metaregmultiple <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Calculate effect sizes and variances using escalc function from metafor
    dat <- escalc(measure = input$effectMeasure,  # "MD" for Mean Difference or "SMD" for Standardized Mean Difference
                  m1i = dat$meanintervention,
                  sd1i = dat$sdintervention,
                  n1i = dat$totalintervention,
                  m2i = dat$meancontrol,
                  sd2i = dat$sdcontrol,
                  n2i = dat$totalcontrol,
                  data = dat,
                  slab = dat$author)
    
    # Fit the random-effects model using rma
    rma.model <- rma(yi = yi, vi = vi, data = dat, method = "REML")
    
    # Check if the moderators are present in the dataset
    if(all(c("Reg", "Reg2", "Reg3") %in% names(dat))) {
      # Fit the random-effects model with moderators
      rma.model.with.mods <- rma(yi = yi, vi = vi, mods = ~ Reg + Reg2 + Reg3, data = dat, method = "REML")
      
      # Plot the results from the random-effects model with moderators
      forest(rma.model.with.mods, main = "Forest Plot of RMA Model with Moderators", 
             xlab = input$effectMeasure == "MD" ? "Mean Difference" : "Standardized Mean Difference", 
             slab = paste(dat$author))
      
    } else {
      # If moderators are not available, use the basic model for plotting
      forest(rma.model, main = "Forest Plot of Basic RMA Model", 
             xlab = input$effectMeasure == "MD" ? "Mean Difference" : "Standardized Mean Difference", 
             slab = paste(dat$author))
    }
  })
  
  
  output$resultText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    # Print the summary of the meta-analysis
    print(summary(m.bin))
  }
  )
  
  library(magrittr)       # For the pipe operator
  library(PerformanceAnalytics)  # For chart.Correlation
  library(metafor)        # For rma (random-effects model)
  library(dplyr)          # For data manipulation
  
  output$mmreg <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Calculate effect sizes and variances using escalc function from metafor
    dat <- escalc(measure = input$effectMeasure,      # "MD" for Mean Difference or "SMD" for Standardized Mean Difference
                  m1i = dat$meanintervention,
                  sd1i = dat$sdintervention,
                  n1i = dat$totalintervention,
                  m2i = dat$meancontrol,
                  sd2i = dat$sdcontrol,
                  n2i = dat$totalcontrol,
                  data = dat,
                  slab = dat$author)
    
    # Fit the random-effects model using rma
    rma.model <- rma(yi = yi, vi = vi, data = dat, method = "REML")
    
    # Check if moderators are present
    if(all(c("Reg", "Reg2", "Reg3") %in% names(dat))) {
      # Fit the random-effects model with moderators
      rma.model.with.mods <- rma(yi = yi, vi = vi, mods = ~ Reg + Reg2 + Reg3, data = dat, method = "REML")
      
      # Extracting the fitted model data for correlation chart
      fit.data <- cbind(dat[ ,c("Reg", "Reg2", "Reg3")], Residuals = resid(rma.model.with.mods))
      
      # Generate correlation plot for the moderators and the residuals
      fit.data %>% 
        PerformanceAnalytics::chart.Correlation(histogram=TRUE, pch=19)
      
    } else {
      # If moderators are not available, use basic data for correlation chart
      base.data <- dat %>%
        dplyr::select(yi, vi)
      
      # Generate correlation plot for effect sizes and their variances
      base.data %>% 
        PerformanceAnalytics::chart.Correlation(histogram=TRUE, pch=19)
    }
  })
  
  
  
  library(metafor)  # For meta-analysis via rma
  library(dmetar)   # For multimodel inference
  library(dplyr)    # For data manipulation
  
  output$metaregmultiple <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Calculate effect sizes and variances using escalc function from metafor
    dat <- escalc(measure = input$effectMeasure,      # "MD" for Mean Difference or "SMD" for Standardized Mean Difference
                  m1i = dat$meanintervention,
                  sd1i = dat$sdintervention,
                  n1i = dat$totalintervention,
                  m2i = dat$meancontrol,
                  sd2i = dat$sdcontrol,
                  n2i = dat$totalcontrol,
                  data = dat,
                  slab = dat$author)
    
    # Fit the random-effects model using rma
    rma.model <- rma(yi = yi, vi = vi, data = dat, method = "REML")
    
    # Check if the moderators are present in the dataset
    if(all(c("Reg", "Reg2", "Reg3") %in% names(dat))) {
      cat("\nModerator Analysis:\n")
      # Fit the random-effects model with moderators
      rma.model.with.mods <- rma(yi = yi, vi = vi, mods = ~ Reg + Reg2 + Reg3, data = dat, method = "REML")
      print(summary(rma.model.with.mods))
      
      # Compute the correlation matrix for the moderators
      cat("\nCorrelation Matrix for Moderators:\n")
      correlation_matrix <- cor(dat[,c("Reg", "Reg2", "Reg3")])
      print(correlation_matrix)
      
      # Perform multimodel inference using dmetar
      cat("\nMultimodel Inference from dmetar:\n")
      multi.inference.results <- multimodel.inference(rma.model.with.mods)
      print(multi.inference.results)
      
    } else {
      cat("The specified moderators are not present in the dataset.")
    }
    
    # Perform a permutation test for the overall effect size
    cat("\nPermutation Test for the Overall Effect Size:\n")
    perm.test.results <- permutest(rma.model, nperm = 999)
    print(perm.test.results)
  })
  
  
  
  output$RMAodd <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Calculate effect sizes and variances using escalc function from metafor
    dat <- escalc(measure = input$effectMeasure,      # "MD" for Mean Difference or "SMD" for Standardized Mean Difference
                  m1i = dat$meanintervention,
                  sd1i = dat$sdintervention,
                  n1i = dat$totalintervention,
                  m2i = dat$meancontrol,
                  sd2i = dat$sdcontrol,
                  n2i = dat$totalcontrol,
                  data = dat,
                  slab = dat$author)
    
    # Fit the random-effects model using rma
    rma.model <- rma(yi = dat$yi, vi = dat$vi, data = dat, method = "REML")
    
    # Print a detailed summary of the fitted model
    cat("Detailed Summary of Random-Effects Meta-Analysis:\n")
    print(summary(rma.model))
    
    # Additional details can be included such as confidence intervals, prediction intervals, etc.
    cat("\nConfidence Interval for the Overall Effect Size:\n")
    print(confint(rma.model))
    
    cat("\nTest for Residual Heterogeneity:\n")
    print(anova(rma.model))
    
    cat("\nTest for Overall Effect:\n")
    print(rma.model$test)
    
    # Include diagnostics for influential studies
    cat("\nInfluential Studies Diagnostics:\n")
    inf <- influence(rma.model)
    print(inf)
  })
  
  
  output$hetro <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Eggers test for funnel plot asymmetry
    m.genp <- eggers.test(m.bin)
    
    # Find outliers in the meta-analysis
    m.gen.out <- find.outliers(m.bin)
    
    # Influence analysis
    m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
    
    # Print Eggers test summary
    print(summary(m.genp))
    
    # Print outlier analysis summary
    print(summary(m.gen.out))
    
    # Print influence analysis results including DFFITS and Cook's Distance
    print(summary(m.gen.inf))
    
    # Extract heterogeneity measures from meta-analysis results
    heterogeneity_stats <- list(
      "Cochrane's Q" = m.bin$Q,
      "I2" = m.bin$I2,
      "H2" = m.bin$H2,
      "Tau^2" = m.bin$tau^2,
      "Tau" = sqrt(m.bin$tau^2)
    )
    
    # Print heterogeneity statistics
    print(heterogeneity_stats)
  })
  
  
  output$pubbias <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    m.limitmeta <-limitmeta(m.bin)
    # Use tryCatch to handle errors in pcurve
    p.curve <- tryCatch({
      pcurve(m.bin)
    }, error = function(e) {
      NULL  # Return NULL or a custom message if pcurve fails
    })
    
    print(summary( m.limitmeta))
    # Only print the p.curve summary if it was successful
    if (!is.null(p.curve)) {
      print(summary(p.curve))
    } else {
      cat("p-curve analysis could not be conducted.\n")
    }
  })
  
  output$metareg <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    m.gen.reg <- metareg(m.bin, ~Reg)
    
    print(summary( m.gen.reg))
    
  })
  
  
  
  output$forestPlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    forest(m.bin, 
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           label.left = input$label,
           label.right = input$labelr,
           xlim = input$xRange,
           prediction = TRUE )
  })
  
  output$forestPlotJAMA <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    forest(m.bin, 
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           prediction = FALSE,
           layout = "JAMA")
    
  })
  
  output$forestPlotRevman5 <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    forest(m.bin, 
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           prediction = FALSE,
           layout = "RevMan5")
  }, height = reactive(input$plotHeight), width = reactive(input$plotWidth))
  
  output$downloadPlotRevman5 <- downloadHandler(
    filename = function() {
      paste("forest_plot_revman5", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      # Convert the data to appropriate format for metacont
      m.bin <- metacont(n.e = dat$totalintervention,
                        mean.e = dat$meanintervention,
                        sd.e = dat$sdintervention,
                        n.c = dat$totalcontrol,
                        mean.c = dat$meancontrol,
                        sd.c = dat$sdcontrol,
                        studlab = dat$author,
                        data = dat,
                        sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                        method.smd = input$method.smd,
                        method.tau = input$method.tau,
                        comb.fixed = input$effectModel == "FE",
                        comb.random = input$effectModel == "RE")
      
      print(summary(m.bin))
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE,
             layout = "RevMan5")
      dev.off()
    }
  )
  
  output$forestPlotRevman5 <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    forest(m.bin, 
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           prediction = FALSE,
           layout = "RevMan5")
  }, height = reactive(input$plotHeight), width = reactive(input$plotWidth))
  
  output$downloadPlotJAMA <- downloadHandler(
    filename = function() {
      paste("forest_plot_JAMA", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      # Convert the data to appropriate format for metacont
      m.bin <- metacont(n.e = dat$totalintervention,
                        mean.e = dat$meanintervention,
                        sd.e = dat$sdintervention,
                        n.c = dat$totalcontrol,
                        mean.c = dat$meancontrol,
                        sd.c = dat$sdcontrol,
                        studlab = dat$author,
                        data = dat,
                        sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                        method.smd = input$method.smd,
                        method.tau = input$method.tau,
                        comb.fixed = input$effectModel == "FE",
                        comb.random = input$effectModel == "RE")
      
      print(summary(m.bin))
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE,
             layout = "JAMA")
      dev.off()
    }
  )
  
  output$forestPlotRevman5 <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    forest(m.bin, 
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           prediction = FALSE,
           layout = "RevMan5")
  }, height = reactive(input$plotHeight), width = reactive(input$plotWidth))
  
  output$downloadPlotmeta <- downloadHandler(
    filename = function() {
      paste("forest_plot_meta", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      # Convert the data to appropriate format for metacont
      m.bin <- metacont(n.e = dat$totalintervention,
                        mean.e = dat$meanintervention,
                        sd.e = dat$sdintervention,
                        n.c = dat$totalcontrol,
                        mean.c = dat$meancontrol,
                        sd.c = dat$sdcontrol,
                        studlab = dat$author,
                        data = dat,
                        sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                        method.smd = input$method.smd,
                        method.tau = input$method.tau,
                        comb.fixed = input$effectModel == "FE",
                        comb.random = input$effectModel == "RE")
      
      print(summary(m.bin))
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE)
      dev.off()
    })
  
  
  output$beeswarm <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Assuming 'author' is a column in 'dat'
    author <- dat$author
    
    # Run the meta-analysis
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Prepare data for bee swarm plot
    summary_data <- summary(m.bin)
    plot_data <- data.frame(
      Study = dat$author,  # Use author data directly from input data
      TE = summary_data$TE,
      SE = summary_data$seTE,
      Weight = summary_data$w.fixed + summary_data$w.random  # Total weight, fixed + random
    )
    
    # Using ggbeeswarm to create a Bee Swarm Plot
    ggplot(plot_data, aes(x = factor(1), y = TE, size = Weight)) +  # 'factor(1)' to align all points vertically
      geom_beeswarm(cex = 1.5) +
      geom_hline(yintercept = 0, linetype = "dashed", color = "red") +  # Add a reference line at no effect
      labs(x = "", y = "Effect Size (e.g., Odds Ratio)", title = "Bee Swarm Plot of Study Effects") +
      theme_minimal() +
      theme(axis.text.x = element_blank(), axis.title.x = element_blank())
  })
  output$BubblePlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    
    # Identify available moderator columns
    moderators <- c()
    if("Reg" %in% names(dat)) moderators <- c(moderators, "Reg")
    if("Reg2" %in% names(dat)) moderators <- c(moderators, "Reg2")
    if("Reg3" %in% names(dat)) moderators <- c(moderators, "Reg3")
    
    n_mod <- length(moderators)
    if(n_mod == 0) {
      plot.new()
      text(0.5, 0.5, "No moderator columns found for bubble plots.", cex = 1.5)
    } else {
      # Set up a layout with one row per moderator
      par(mfrow = c(n_mod, 1), mar = c(4, 4, 3, 1))
      for(mod in moderators) {
        # Build a simple meta-regression model for this moderator alone
        formula_text <- paste("~", mod)
        m.reg <- metareg(m.bin, as.formula(formula_text))
        
        # Create a bubble plot for the moderator
        bubble(m.reg, studlab = TRUE, main = paste("Bubble Plot for Moderator:", mod))
      }
      # Reset plotting parameters to default
      par(mfrow = c(1, 1))
    }
  })
  output$singleBubblePlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Check if the selected moderator exists in the data
    if (!(input$selectedModerator %in% names(dat))) {
      plot.new()
      text(0.5, 0.5, paste("Moderator", input$selectedModerator, "not found in data."), cex = 1.5)
    } else {
      # Create the meta-analysis object using metacont()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      
      # Build a meta-regression model using the selected moderator
      m.reg <- metareg(m.bin, as.formula(paste("~", input$selectedModerator)))
      
      # Create the bubble plot for the selected moderator
      bubble(m.reg, studlab = TRUE, main = paste("Bubble Plot for Moderator:", input$selectedModerator))
    }
  })
  
  
  output$radial <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    
    radial(m.bin)
  })
  output$drapery <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    drapery(m.bin, 
            labels = "studlab",
            type = "pval", 
            legend = FALSE)
  })
  
  output$cforest <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Run the meta-analysis
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Calculate z-values
    z_values <- summary(m.bin)$TE / summary(m.bin)$seTE
    
    # Calculate p-values
    p_values <- 2 * (1 - pnorm(abs(z_values)))
    
    # Prepare data for plotting
    # Ensure n_treatment and n_control are correctly defined or calculated from 'dat'
    n_treatment <- dat$totalintervention
    n_control <- dat$totalcontrol
    plot_data <- data.frame(
      SampleSize = n_treatment + n_control,
      PValue = p_values
    )
    
    # Create the Albatross Plot
    ggplot(plot_data, aes(x = log(SampleSize), y = -log10(PValue))) +
      geom_point() +
      geom_smooth(method = "lm", se = FALSE, color = "blue") +
      labs(x = "Log of Sample Size", y = "-Log10 of P-value", title = "Albatross Plot") +
      theme_minimal()
  })
  
  output$Baujatplot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
    plot(m.gen.inf, "baujat")
    
  })
  
  output$Influence <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
    plot(m.gen.inf, "influence")
    
  })
  output$effectsize <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
    plot(m.gen.inf, "es")
    
  })
  output$I2 <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
    plot(m.gen.inf, "i2")
    
  })
  output$lm2 <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    lm2 <-limitmeta(m.bin)
    funnel.limitmeta(lm2,shrunken = TRUE)
    
  })
  output$lm <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    lm <-limitmeta(m.bin)
    funnel.limitmeta(lm)
    
  })
  output$rainforest <- renderPlot({
    req(dataInput())
    dat <- dataInput()  # Assuming dataInput() loads the data correctly
    
    # Run the meta-analysis
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Prepare data for Rainforest plot
    summary_data <- summary(m.bin)
    plot_data <- data.frame(
      Study = dat$author,  # Use author data directly from input data
      TE = summary_data$TE,
      Lower = summary_data$lower,
      Upper = summary_data$upper,
      Year = dat$year,
      Reg = dat$Reg
    )
    
    # Using ggplot2 to create a Rainforest Plot
    ggplot(plot_data, aes(x = TE, y = Study, ymin = Lower, ymax = Upper, color = factor(Reg))) +
      geom_pointrange() +
      geom_vline(xintercept = 0, linetype = "dashed") +
      facet_wrap(~Year, scales = "free") +
      labs(x = "Effect Size", y = "Study", title = "Rainforest Plot") +
      theme_minimal() +
      theme(axis.title.y = element_blank())
  })
  
  
  
  
  output$pcurve <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    lm <- pcurve(m.bin, effect.estimation = FALSE, N, dmin = 0, dmax = 1)
    
    
  })
  
  output$downloadFunnelPlot <- downloadHandler(
    filename = function() {
      paste("funnel_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(n.e = dat$totalintervention,
                        mean.e = dat$meanintervention,
                        sd.e = dat$sdintervention,
                        n.c = dat$totalcontrol,
                        mean.c = dat$meancontrol,
                        sd.c = dat$sdcontrol,
                        studlab = dat$author,
                        data = dat,
                        sm = input$effectMeasure,
                        method.smd = input$method.smd,
                        method.tau = input$method.tau,
                        comb.fixed = (input$effectModel == "FE"),
                        comb.random = (input$effectModel == "RE"))
      col.contour <- c("gray75", "gray85", "gray95")
      if (input$colorFunnel) {
        funnel(m.bin, xlim = input$funnelXRange, 
               contour = c(0.9, 0.95, 0.99), col.contour = col.contour)
        legend("topright", inset = 0.05,
               legend = c("p < 0.1", "p < 0.05", "p < 0.01"),
               fill = col.contour)
        title(main = "Contour-Enhanced Funnel Plot")
      } else {
        funnel(m.bin, xlim = input$funnelXRange)
      }
      dev.off()
    }
  )
  
  
  
  output$ggbee <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Assuming 'author' is a column in 'dat'
    author <- dat$author
    
    # Run the meta-analysis
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Prepare data for bee swarm plot
    summary_data <- summary(m.bin)
    plot_data <- data.frame(
      Study = dat$author,  # Use author data directly from input data
      TE = summary_data$TE,
      SE = summary_data$seTE,
      Weight = summary_data$w.fixed + summary_data$w.random  # Total weight, fixed + random
    )
    
    # Using ggbeeswarm to create a Bee Swarm Plot
    ggplot(plot_data, aes(x = factor(1), y = TE, size = Weight)) +  # 'factor(1)' to align all points vertically
      geom_beeswarm(cex = 1.5) +
      geom_hline(yintercept = 0, linetype = "dashed", color = "red") +  # Add a reference line at no effect
      labs(x = "", y = "Effect Size (e.g., Odds Ratio)", title = "Bee Swarm Plot of Study Effects") +
      theme_minimal() +
      theme(axis.text.x = element_blank(), axis.title.x = element_blank())
  })
  
  output$subgroupText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    if(!("subgroup" %in% names(dat))){
      cat("No subgroup column found in the data. Please include a 'subgroup' column.")
    } else {
      # Create a meta-analysis object with subgroup analysis using the byvar argument
      m.subgroup <- metacont(n.e = dat$totalintervention,
                             mean.e = dat$meanintervention,
                             sd.e = dat$sdintervention,
                             n.c = dat$totalcontrol,
                             mean.c = dat$meancontrol,
                             sd.c = dat$sdcontrol,
                             studlab = dat$author,
                             data = dat,
                             sm = input$effectMeasure,
                             byvar = dat$subgroup,       # subgroup variable for analysis
                             print.byvar = TRUE,
                             method.smd = input$method.smd,
                             method.tau = input$method.tau,
                             comb.fixed = (input$effectModel == "FE"),
                             comb.random = (input$effectModel == "RE"))
      
      # Print the subgroup analysis summary
      print(summary(m.subgroup))
    }
  })
  output$forestPlotSubgroup <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    if(!("subgroup" %in% names(dat))){
      # If no subgroup column is found, display a message
      plot.new()
      text(0.5, 0.5, "No subgroup column found in the data.", cex = 1.5)
    } else {
      # Create a meta-analysis object with subgroup analysis using the byvar argument
      m.subgroup <- metacont(n.e = dat$totalintervention,
                             mean.e = dat$meanintervention,
                             sd.e = dat$sdintervention,
                             n.c = dat$totalcontrol,
                             mean.c = dat$meancontrol,
                             sd.c = dat$sdcontrol,
                             studlab = dat$author,
                             data = dat,
                             sm = input$effectMeasure,
                             byvar = dat$subgroup,       # subgroup variable
                             print.byvar = TRUE,
                             method.smd = input$method.smd,
                             method.tau = input$method.tau,
                             comb.fixed = (input$effectModel == "FE"),
                             comb.random = (input$effectModel == "RE"))
      
      # Display the forest plot using the same options as for the other forest plots
      forest(m.subgroup,
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             label.left = input$label,
             label.right = input$labelr,
             xlim = input$xRange,
             prediction = TRUE)
    }
  })
  
  
  output$Trimfill <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    
    # Convert the data to appropriate format for metacont
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,      # Choose between "SMD" or "MD"
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    tf <- trimfill(m.bin)
    # Define fill colors for contour
    contour <- c(0.9, 0.95, 0.99)
    col.contour <- c("gray75", "gray85", "gray95")
    ld <- c("p < 0.1", "p < 0.05", "p < 0.01")
    
    
    # Contour-enhanced funnel plot (full data)
    meta::funnel(tf, 
                 contour = contour,
                 col.contour = col.contour)
    legend(x = 1.1, y = 0.01, 
           legend = ld, fill = col.contour)
    title("Funnel Plot (Trim & Fill Method)")
    
    
  })
  
  output$cumMetaText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = (input$effectModel == "FE"),
                      comb.random = (input$effectModel == "RE"))
    
    # If a "year" column exists, sort the studies by year for cumulative analysis;
    # otherwise, use the current study order.
    if("year" %in% names(dat)){
      m.cum <- metacum(m.bin, sortvar = dat$year)
    } else {
      m.cum <- metacum(m.bin)
    }
    
    # Display the cumulative meta-analysis summary
    print(summary(m.cum))
  })
  
  output$cumForestPlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = (input$effectModel == "FE"),
                      comb.random = (input$effectModel == "RE"))
    
    # Create the cumulative meta-analysis object. If a "year" column exists, sort by year.
    if("year" %in% names(dat)){
      m.cum <- metacum(m.bin, sortvar = dat$year)
    } else {
      m.cum <- metacum(m.bin)
    }
    
    # Plot the cumulative forest plot with the same styling options
    forest(m.cum,
           col.diamond = input$col.diamond,
           col.diamond.lines = input$col.diamond.lines,
           col.square = input$col.square,
           col.square.lines = input$col.square.lines,
           col.study = input$col.study,
           col.circle = input$col.circle,
           col.circle.lines = input$col.circle.lines,
           labstudies = input$labstudies,
           cex = input$textsize,
           lwd = input$linewidth,
           label.left = input$label,
           label.right = input$labelr,
           xlim = input$xRange,
           prediction = TRUE)
  })
  output$singleMetaregText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object using metacont()
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    
    # Check if both "Reg" and "Reg2" columns are available for two moderator analysis
    if(!("Reg" %in% names(dat)) || !("Reg2" %in% names(dat))) {
      cat("Moderator columns 'Reg' and/or 'Reg2' not found in the data. Please include columns named 'Reg' and 'Reg2' for two moderator meta-regression.")
    } else {
      # Perform two moderator meta-regression
      m.reg <- metareg(m.bin, ~ Reg + Reg2)
      print(summary(m.reg))
    }
  })
  output$threeMetaregText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object using metacont()
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    
    # Check if the moderator columns are available for three moderator analysis
    if (!("Reg" %in% names(dat)) || !("Reg2" %in% names(dat)) || !("Reg3" %in% names(dat))) {
      cat("One or more moderator columns ('Reg', 'Reg2', 'Reg3') are missing in the data. Please include columns named 'Reg', 'Reg2', and 'Reg3' for three moderator meta-regression.")
    } else {
      # Perform three moderator meta-regression
      m.reg <- metareg(m.bin, ~ Reg + Reg2 + Reg3)
      print(summary(m.reg))
    }
  })
  output$timeTrendText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    
    # Check if a "year" column exists for the time trend analysis
    if(!("year" %in% names(dat))){
      cat("No 'year' column found in the data. Please include a 'year' column for time-trend meta-regression.")
    } else {
      # Perform meta-regression using 'year' as the moderator
      m.regTime <- metareg(m.bin, ~ year)
      print(summary(m.regTime))
    }
  })
  
  
  library(dosresmeta)
  
  output$doseResponseText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Required columns for dose-response analysis
    required_cols <- c("study", "dose", "logRR", "se_logRR", "cases", "n", "type")
    missing_cols <- setdiff(required_cols, names(dat))
    if(length(missing_cols) > 0) {
      cat("Missing required columns for dose-response analysis:", 
          paste(missing_cols, collapse = ", "))
      return(NULL)
    }
    
    # Convert necessary columns to proper types
    dat$study    <- as.character(dat$study)
    dat$dose     <- as.numeric(dat$dose)
    dat$logRR    <- as.numeric(dat$logRR)
    dat$se_logRR <- as.numeric(dat$se_logRR)
    dat$cases    <- as.numeric(dat$cases)
    dat$n        <- as.numeric(dat$n)
    dat$type     <- as.character(dat$type)
    
    # Sort data by study and dose
    dat <- dat[order(dat$study, dat$dose), ]
    
    # Check that each study has at least two unique dose levels
    study_counts <- tapply(dat$dose, dat$study, function(x) length(unique(x)))
    cat("Study unique dose counts:\n")
    print(study_counts)
    if (any(study_counts < 2)) {
      cat("Error: Each study must have at least 2 unique dose levels. The following studies have less than 2: ", 
          paste(names(study_counts)[study_counts < 2], collapse = ", "))
      return(NULL)
    }
    
    # If all studies have exactly two unique dose levels, use covariance "indep"; otherwise, use "h"
    cov_option <- if (all(study_counts == 2)) "indep" else "h"
    cat("Using covariance option:", cov_option, "\n")
    
    # Center the dose variable at its overall mean
    center_value <- mean(dat$dose, na.rm = TRUE)
    cat("Centering dose variable at:", center_value, "\n")
    
    # Try to fit the dose-response meta-analysis model
    tryCatch({
      dr_model <- dosresmeta(
        formula = logRR ~ dose,
        id = factor(dat$study),
        cases = dat$cases,
        n = dat$n,
        type = dat$type,
        se = dat$se_logRR,
        data = dat,
        method = "reml",
        covariance = cov_option,
        center = center_value
      )
      print(summary(dr_model))
    }, error = function(e) {
      cat("Error in dosresmeta: ", e$message)
    })
  })
  output$doseResponsePlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Required columns for dose-response analysis
    required_cols <- c("study", "dose", "logRR", "se_logRR", "cases", "n", "type")
    missing_cols <- setdiff(required_cols, names(dat))
    if(length(missing_cols) > 0) {
      plot.new()
      text(0.5, 0.5, paste("Missing required columns:", paste(missing_cols, collapse = ", ")), cex = 1.5)
      return()
    }
    
    # Convert necessary columns to appropriate types
    dat$study    <- as.character(dat$study)
    dat$dose     <- as.numeric(dat$dose)
    dat$logRR    <- as.numeric(dat$logRR)
    dat$se_logRR <- as.numeric(dat$se_logRR)
    dat$cases    <- as.numeric(dat$cases)
    dat$n        <- as.numeric(dat$n)
    dat$type     <- as.character(dat$type)
    
    # Sort data by study and dose
    dat <- dat[order(dat$study, dat$dose), ]
    
    # Check that each study has at least two unique dose levels
    study_counts <- tapply(dat$dose, dat$study, function(x) length(unique(x)))
    if(any(study_counts < 2)) {
      plot.new()
      text(0.5, 0.5, "Each study must have at least 2 unique dose levels.", cex = 1.5)
      return()
    }
    
    # Choose covariance option: if every study has exactly 2 unique doses, use "indep"; otherwise, use "h"
    cov_option <- if(all(study_counts == 2)) "indep" else "h"
    
    # Center the dose variable at its overall mean
    center_value <- mean(dat$dose, na.rm = TRUE)
    
    # Fit the dose-response meta-analysis model
    dr_model <- tryCatch({
      dosresmeta(
        formula = logRR ~ dose,
        id = factor(dat$study),
        cases = dat$cases,
        n = dat$n,
        type = dat$type,
        se = dat$se_logRR,
        data = dat,
        method = "reml",
        covariance = cov_option,
        center = center_value
      )
    }, error = function(e) {
      plot.new()
      text(0.5, 0.5, paste("Error in dosresmeta:", e$message), cex = 1.5)
      return(NULL)
    })
    
    if(is.null(dr_model)) return()  # stop if model fitting failed
    
    # Create a sequence of dose values for prediction
    dose_seq <- seq(min(dat$dose, na.rm = TRUE), max(dat$dose, na.rm = TRUE), length.out = 100)
    
    # Predict the logRR and confidence intervals for the new dose values
    pred <- predict(dr_model, newdata = data.frame(dose = dose_seq))
    
    # Plot the predicted dose-response curve with 95% confidence intervals
    plot(dose_seq, pred$pred, type = "l", lwd = 2,
         xlab = "Dose", ylab = "Log Relative Risk",
         main = "Dose-Response Curve",
         ylim = range(pred$ci.lb, pred$ci.ub, na.rm = TRUE))
    lines(dose_seq, pred$ci.lb, lty = 2, col = "blue", lwd = 1.5)
    lines(dose_seq, pred$ci.ub, lty = 2, col = "blue", lwd = 1.5)
    
    # Optionally add points for observed logRR values
    points(dat$dose, dat$logRR, pch = 16, col = "darkgray")
  })
  
  
  
  
  output$resultText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    if(input$dataType == "SMD"){
      # Standard continuous data: use metacont() as before
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      
    } else if(input$dataType == "OR"){
      # Check if necessary columns exist
      if(!("OR" %in% names(dat)) || !("se_OR" %in% names(dat))){
        cat("Please include 'OR' and 'se_OR' columns for odds ratio data.")
        return(NULL)
      }
      # Convert Odds Ratio to SMD
      dat$convertedSMD <- log(dat$OR) * (sqrt(3) / pi)
      dat$convertedSMD_SE <- dat$se_OR * (sqrt(3) / pi)
      # Create a meta-analysis object using rma() directly on the converted SMD values
      m.bin <- rma(yi = dat$convertedSMD, vi = dat$convertedSMD_SE^2, method = "REML")
      
    } else if(input$dataType == "r"){
      # Check if necessary columns exist
      if(!("r" %in% names(dat)) || !("se_r" %in% names(dat))){
        cat("Please include 'r' and 'se_r' columns for correlation data.")
        return(NULL)
      }
      # Convert correlation to SMD
      dat$convertedSMD <- 2 * dat$r / sqrt(1 - dat$r^2)
      dat$convertedSMD_SE <- 2 * dat$se_r / sqrt(1 - dat$r^2)
      # Create a meta-analysis object using rma() on the converted values
      m.bin <- rma(yi = dat$convertedSMD, vi = dat$convertedSMD_SE^2, method = "REML")
    }
    
    # Print the summary of the meta-analysis
    print(summary(m.bin))
  })
  
  
  
  output$sampleCSV <- renderUI({
    HTML(paste0(
      "<h2>1. Minimal Standard Meta-Analysis (Without Subgroup or Meta-Regression)</h2>",
      "<p>This CSV file contains only the basic columns for a standard meta‑analysis using continuous outcomes.</p>",
      "<pre>",
      "meanintervention,sdintervention,totalintervention,meancontrol,sdcontrol,totalcontrol,author",
      "\n5.0,1.0,50,4.0,1.0,50,StudyA",
      "\n6.0,1.2,60,5.0,1.1,60,StudyB",
      "</pre>",
      
      "<h2>2. Standard Meta-Analysis with Subgroup</h2>",
      "<p>This CSV file includes a subgroup column to allow subgroup analyses.</p>",
      "<pre>",
      "meanintervention,sdintervention,totalintervention,meancontrol,sdcontrol,totalcontrol,author,subgroup",
      "\n5.0,1.0,50,4.0,1.0,50,StudyA,Group1",
      "\n6.0,1.2,60,5.0,1.1,60,StudyB,Group2",
      "</pre>",
      
      "<h2>3. Standard Meta-Analysis with Meta-Regression (Without Year, OR, se_OR, r, se_r)</h2>",
      "<p>This file includes moderator columns for meta‑regression.</p>",
      "<pre>",
      "meanintervention,sdintervention,totalintervention,meancontrol,sdcontrol,totalcontrol,author,Reg,Reg2,Reg3",
      "\n5.0,1.0,50,4.0,1.0,50,StudyA,0.5,1.0,0.8",
      "\n6.0,1.2,60,5.0,1.1,60,StudyB,0.6,1.2,0.7",
      "</pre>",
      
      "<h2>4. Standard Meta-Analysis with Meta-Regression and Additional Columns (Year, OR, se_OR, r, se_r)</h2>",
      "<p>This file includes meta‑regression moderators plus a year column and alternate effect size measures.</p>",
      "<pre>",
      "meanintervention,sdintervention,totalintervention,meancontrol,sdcontrol,totalcontrol,author,Reg,Reg2,Reg3,year,OR,se_OR,r,se_r",
      "\n5.0,1.0,50,4.0,1.0,50,StudyA,0.5,1.0,0.8,2018,1.5,0.2,0.3,0.05",
      "\n6.0,1.2,60,5.0,1.1,60,StudyB,0.6,1.2,0.7,2019,1.7,0.25,0.35,0.06",
      "</pre>",
      
      "<h2>5. Dose-Response Meta-Analysis</h2>",
      "<p>This file includes additional columns for dose–response analysis. The 'study' column (which matches 'author') identifies the study, and each study appears twice with different dose levels. The extra columns required for dose–response are: dose, logRR, se_logRR, cases, n, type.</p>",
      "<pre>",
      "study,dose,logRR,se_logRR,cases,n,type,meanintervention,sdintervention,totalintervention,meancontrol,sdcontrol,totalcontrol,author,subgroup,Reg,Reg2,Reg3,year,OR,se_OR,r,se_r",
      "\nStudyA,5,0.20,0.06,30,100,cohort,5.0,1.0,50,4.0,1.0,50,StudyA,Group1,0.5,1.0,0.8,2018,1.5,0.2,0.3,0.05",
      "\nStudyA,15,0.25,0.07,32,100,cohort,5.2,1.1,50,4.2,1.0,50,StudyA,Group1,0.5,1.0,0.8,2018,1.5,0.2,0.3,0.05",
      "\nStudyB,10,0.30,0.08,35,120,cohort,6.0,1.2,60,5.0,1.1,60,StudyB,Group2,0.6,1.2,0.7,2019,1.7,0.25,0.35,0.06",
      "\nStudyB,20,0.35,0.09,37,120,cohort,6.1,1.3,60,5.2,1.1,60,StudyB,Group2,0.6,1.2,0.7,2019,1.7,0.25,0.35,0.06",
      "</pre>"
    ))
  })
  
  output$downloadBeeswarmPlot <- downloadHandler(
    filename = function() {
      paste("beeswarm_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      summary_data <- summary(m.bin)
      plot_data <- data.frame(
        Study = dat$author,
        TE = summary_data$TE,
        SE = summary_data$seTE,
        Weight = summary_data$w.fixed + summary_data$w.random
      )
      p <- ggplot(plot_data, aes(x = factor(1), y = TE, size = Weight)) +
        geom_beeswarm(cex = 1.5) +
        geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
        labs(x = "", y = "Effect Size", title = "Bee Swarm Plot of Study Effects") +
        theme_minimal() +
        theme(axis.text.x = element_blank(), axis.title.x = element_blank())
      print(p)
      dev.off()
    }
  )
  output$downloadBubblePlot <- downloadHandler(
    filename = function() {
      paste("bubble_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      # Ensure the selected moderator exists
      if (!(input$selectedModerator %in% names(dat))) {
        plot.new()
        text(0.5, 0.5, paste("Moderator", input$selectedModerator, "not found in data."), cex = 1.5)
      } else {
        m.bin <- metacont(
          n.e = dat$totalintervention,
          mean.e = dat$meanintervention,
          sd.e = dat$sdintervention,
          n.c = dat$totalcontrol,
          mean.c = dat$meancontrol,
          sd.c = dat$sdcontrol,
          studlab = dat$author,
          data = dat,
          sm = input$effectMeasure,
          method.smd = input$method.smd,
          method.tau = input$method.tau,
          comb.fixed = (input$effectModel == "FE"),
          comb.random = (input$effectModel == "RE")
        )
        m.reg <- metareg(m.bin, as.formula(paste("~", input$selectedModerator)))
        bubble(m.reg, studlab = TRUE, main = paste("Bubble Plot for Moderator:", input$selectedModerator))
      }
      dev.off()
    }
  )
  output$downloadRadialPlot <- downloadHandler(
    filename = function() {
      paste("radial_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      radial(m.bin)
      dev.off()
    }
  )
  output$downloadDraperyPlot <- downloadHandler(
    filename = function() {
      paste("drapery_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      drapery(m.bin, labels = "studlab", type = "pval", legend = FALSE)
      dev.off()
    }
  )
  
  output$downloadPlotmeta <- downloadHandler(
    filename = function() {
      paste("RMA_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE)
      dev.off()
    }
  )
  output$downloadCforestPlot <- downloadHandler(
    filename = function() {
      paste("albatross_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      # Using metacont to compute meta-analysis object for effect sizes and variances
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      # cforest (Albatross) plot
      # Calculate z-values and p-values as in your renderPlot
      z_values <- summary(m.bin)$TE / summary(m.bin)$seTE
      p_values <- 2 * (1 - pnorm(abs(z_values)))
      n_treatment <- dat$totalintervention
      n_control <- dat$totalcontrol
      plot_data <- data.frame(
        SampleSize = n_treatment + n_control,
        PValue = p_values
      )
      p <- ggplot(plot_data, aes(x = log(SampleSize), y = -log10(PValue))) +
        geom_point() +
        geom_smooth(method = "lm", se = FALSE, color = "blue") +
        labs(x = "Log of Sample Size", y = "-Log10 of P-value", title = "Albatross Plot") +
        theme_minimal()
      print(p)
      dev.off()
    }
  )
  output$downloadBaujatPlot <- downloadHandler(
    filename = function() {
      paste("baujat_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
      plot(m.gen.inf, "baujat")
      dev.off()
    }
  )
  output$downloadInfluencePlot <- downloadHandler(
    filename = function() {
      paste("influence_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
      plot(m.gen.inf, "influence")
      dev.off()
    }
  )
  output$downloadEffectSizePlot <- downloadHandler(
    filename = function() {
      paste("effect_size_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      m.gen.inf <- InfluenceAnalysis(m.bin, random = TRUE)
      plot(m.gen.inf, "es")
      dev.off()
    }
  )
  output$downloadLMPlot <- downloadHandler(
    filename = function() {
      paste("limitmeta_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      lm_obj <- limitmeta(m.bin)
      funnel.limitmeta(lm_obj)
      dev.off()
    }
  )
  output$downloadLM2Plot <- downloadHandler(
    filename = function() {
      paste("limitmeta_shrunken_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      lm_obj <- limitmeta(m.bin)
      funnel.limitmeta(lm_obj, shrunken = TRUE)
      dev.off()
    }
  )
  output$downloadRainforestPlot <- downloadHandler(
    filename = function() {
      paste("rainforest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      summary_data <- summary(m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      ))
      plot_data <- data.frame(
        Study = dat$author,
        TE = summary_data$TE,
        Lower = summary_data$lower,
        Upper = summary_data$upper,
        Year = dat$year,
        Reg = dat$Reg
      )
      p <- ggplot(plot_data, aes(x = TE, y = Study, ymin = Lower, ymax = Upper, color = factor(Reg))) +
        geom_pointrange() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        facet_wrap(~Year, scales = "free") +
        labs(x = "Effect Size", y = "Study", title = "Rainforest Plot") +
        theme_minimal() +
        theme(axis.title.y = element_blank())
      print(p)
      dev.off()
    }
  )
  output$downloadPcurvePlot <- downloadHandler(
    filename = function() {
      paste("pcurve_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      lm_obj <- pcurve(m.bin, effect.estimation = FALSE, dmin = 0, dmax = 1)
      if(!is.null(lm_obj)){
        print(summary(lm_obj))
      }
      dev.off()
    }
  )
  output$downloadBubblePlot <- downloadHandler(
    filename = function() {
      paste("bubble_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      if (!(input$selectedModerator %in% names(dat))) {
        plot.new()
        text(0.5, 0.5, paste("Moderator", input$selectedModerator, "not found."), cex = 1.5)
      } else {
        m.bin <- metacont(
          n.e = dat$totalintervention,
          mean.e = dat$meanintervention,
          sd.e = dat$sdintervention,
          n.c = dat$totalcontrol,
          mean.c = dat$meancontrol,
          sd.c = dat$sdcontrol,
          studlab = dat$author,
          data = dat,
          sm = input$effectMeasure,
          method.smd = input$method.smd,
          method.tau = input$method.tau,
          comb.fixed = (input$effectModel == "FE"),
          comb.random = (input$effectModel == "RE")
        )
        m.reg <- metareg(m.bin, as.formula(paste("~", input$selectedModerator)))
        bubble(m.reg, studlab = TRUE, main = paste("Bubble Plot for Moderator:", input$selectedModerator))
      }
      dev.off()
    }
  )
  output$downloadCumForestPlot <- downloadHandler(
    filename = function() {
      paste("cumulative_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      if("year" %in% names(dat)){
        m.cum <- metacum(m.bin, sortvar = dat$year)
      } else {
        m.cum <- metacum(m.bin)
      }
      forest(m.cum,
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             label.left = input$label,
             label.right = input$labelr,
             xlim = input$xRange,
             prediction = TRUE)
      dev.off()
    }
  )
  output$downloadTimeTrendPlot <- downloadHandler(
    filename = function() {
      paste("time_trend_meta_regression_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      if(!("year" %in% names(dat))){
        plot.new()
        text(0.5, 0.5, "No 'year' column found for time-trend meta-regression.", cex = 1.5)
      } else {
        m.regTime <- metareg(m.bin, ~ year)
        plot(m.regTime)
      }
      dev.off()
    }
  )
  output$downloadPlotmeta <- downloadHandler(
    filename = function() {
      paste("RMA_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE)
      dev.off()
    }
  )
  output$downloadPlotmeta <- downloadHandler(
    filename = function() {
      paste("RMA_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             prediction = FALSE)
      dev.off()
    }
  )
  output$downloadForestPlot <- downloadHandler(
    filename = function() {
      paste("ordinary_forest_plot_", Sys.Date(), ".png", sep = "")
    },
    content = function(file) {
      png(file, width = input$plotWidth, height = input$plotHeight)
      dat <- dataInput()
      m.bin <- metacont(
        n.e = dat$totalintervention,
        mean.e = dat$meanintervention,
        sd.e = dat$sdintervention,
        n.c = dat$totalcontrol,
        mean.c = dat$meancontrol,
        sd.c = dat$sdcontrol,
        studlab = dat$author,
        data = dat,
        sm = input$effectMeasure,
        method.smd = input$method.smd,
        method.tau = input$method.tau,
        comb.fixed = (input$effectModel == "FE"),
        comb.random = (input$effectModel == "RE")
      )
      forest(m.bin, 
             col.diamond = input$col.diamond,
             col.diamond.lines = input$col.diamond.lines,
             col.square = input$col.square,
             col.square.lines = input$col.square.lines,
             col.study = input$col.study,
             col.circle = input$col.circle,
             col.circle.lines = input$col.circle.lines,
             labstudies = input$labstudies,
             cex = input$textsize,
             lwd = input$linewidth,
             label.left = input$label,
             label.right = input$labelr,
             xlim = input$xRange,
             prediction = TRUE)
      dev.off()
    }
  )
  
  output$leaveOneOutText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Create the basic meta-analysis object using metacont()
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,      # "SMD" or "MD"
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    
    # Perform leave-one-out sensitivity analysis
    loo <- metainf(m.bin)
    
    # Print the leave-one-out analysis summary
    print(loo)
  })
  
  output$bayesianMetaText <- renderPrint({
    req(dataInput())
    dat <- dataInput()
    
    # Check if there are at least 2 studies
    if(nrow(dat) < 2){
      cat("At least 2 studies are required for Bayesian meta-analysis.")
      return()
    }
    
    # Calculate effect sizes and variances using escalc() from metafor
    dat <- escalc(
      measure = input$effectMeasure,  # "MD" or "SMD"
      m1i = dat$meanintervention,
      sd1i = dat$sdintervention,
      n1i = dat$totalintervention,
      m2i = dat$meancontrol,
      sd2i = dat$sdcontrol,
      n2i = dat$totalcontrol,
      data = dat,
      slab = dat$author
    )
    
    # Compute standard errors from variances
    sigma <- sqrt(dat$vi)
    if(any(!is.finite(sigma))){
      cat("Non-finite standard error values encountered. Please check your data.")
      return()
    }
    
    if(length(dat$yi) != length(sigma)){
      cat("Mismatch between effect sizes and standard errors.")
      return()
    }
    
    # Load the bayesmeta package
    library(bayesmeta)
    
    # Fit a Bayesian meta-analysis model.
    # Note: the bayesmeta function expects the effect sizes to be passed with the argument 'y'
    bmeta <- bayesmeta(y = dat$yi, sigma = sigma)
    
    # Print the summary of the Bayesian meta-analysis model
    print(summary(bmeta))
  })
  
  metaTextOutput <- reactive({
    req(dataInput())
    dat <- dataInput()
    # Re-run your meta-analysis (adjust parameters as needed)
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,      # "SMD" or "MD"
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      comb.fixed = (input$effectModel == "FE"),
      comb.random = (input$effectModel == "RE")
    )
    # Capture the printed summary text
    txt <- capture.output(print(summary(m.bin)))
    paste(txt, collapse = "\n")
  })
  
  # Observe button to convert the meta-analysis text using Gemini API
  observeEvent(input$convertAllText, {
    # Get the meta-analysis text from our reactive
    originalText <- metaTextOutput()
    
    # Build the prompt with instructions for rewriting
    prompt <- paste(
      "Rewrite the following meta-analysis text in four different styles:",
      "1. NEJM style",
      "2. Lancet style",
      "3. Cochrane style",
      "4. A version suitable for the public",
      "\n\nOriginal Meta-Analysis Text:\n",
      originalText
    )
    
    # Gemini API endpoint with your API key (ensure the key is valid)
    gemini_url <- "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=AIzaSyAydG28jErd8P2JJ76nXtDVWk-OXcFXR6c"
    
    # Build the request body as required by the Gemini API
    body_payload <- list(
      contents = list(
        list(
          parts = list(
            list(text = prompt)
          )
        )
      )
    )
    
    # Call the Gemini API using a POST request
    response <- POST(
      url = gemini_url,
      add_headers("Content-Type" = "application/json"),
      encode = "json",
      body = body_payload
    )
    
    # Parse the API response as text (adjust parsing if you need structured output)
    result_text <- content(response, as = "text", encoding = "UTF-8")
    
    # Render the converted text into the "Converted Text" tab
    output$convertedText <- renderText({ result_text })
  })
  
  library(glue)
  library(meta)
  
  # Assume dataInput() is already defined (reads the CSV file)
  
  # Define a reactive meta‑analysis result using metacont()
  metaResult <- reactive({
    req(dataInput())
    dat <- dataInput()
    metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,         # "SMD" or "MD"
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      common = (input$effectModel == "FE"),   # updated from comb.fixed
      random = (input$effectModel == "RE")      # updated from comb.random
    )
  })
  
  ### 1. OVERALL META‑ANALYSIS RESULTS
  
  # Cochrane style overall results (including total population numbers)
  output$overall_dynamic_cochrane <- renderText({
    req(metaResult(), dataInput())
    m.bin <- metaResult()
    dat <- dataInput()
    
    k         <- m.bin$k
    effect    <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb     <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub     <- round(as.numeric(m.bin$upper.random), 2)
    p_val     <- as.numeric(m.bin$pval.random)
    significance <- if(p_val < 0.05) "statistically significant" else "not statistically significant"
    
    total_int <- sum(dat$totalintervention, na.rm = TRUE)
    total_ctrl<- sum(dat$totalcontrol, na.rm = TRUE)
    
    glue("
Cochrane Overall Results:

A comprehensive meta-analysis of {k} studies—including a total of {total_int} participants in the intervention group and {total_ctrl} in the control group—yielded a pooled effect estimate of {effect} (95% CI: {ci_lb} to {ci_ub}). This result is {significance} (p = {signif(p_val, 3)}).
")
  })
  
  # NEJM style overall results
  output$overall_dynamic_nejm <- renderText({
    req(metaResult(), dataInput())
    m.bin <- metaResult()
    dat <- dataInput()
    
    k         <- m.bin$k
    effect    <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb     <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub     <- round(as.numeric(m.bin$upper.random), 2)
    p_val     <- as.numeric(m.bin$pval.random)
    significance <- if(p_val < 0.05) "statistically significant" else "not statistically significant"
    
    total_int <- sum(dat$totalintervention, na.rm = TRUE)
    total_ctrl<- sum(dat$totalcontrol, na.rm = TRUE)
    
    glue("
NEJM Overall Results:

Our meta-analysis, which combined {k} studies with {total_int} subjects in the treatment arm and {total_ctrl} in the control arm, produced a pooled effect of {effect} (95% CI: {ci_lb} to {ci_ub}). This effect is {significance} (p = {signif(p_val, 3)}), suggesting that the intervention has clinical importance.
")
  })
  
  # Lancet style overall results
  output$overall_dynamic_lancet <- renderText({
    req(metaResult(), dataInput())
    m.bin <- metaResult()
    dat <- dataInput()
    
    k         <- m.bin$k
    effect    <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb     <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub     <- round(as.numeric(m.bin$upper.random), 2)
    p_val     <- as.numeric(m.bin$pval.random)
    significance <- if(p_val < 0.05) "significant" else "not significant"
    
    total_int <- sum(dat$totalintervention, na.rm = TRUE)
    total_ctrl<- sum(dat$totalcontrol, na.rm = TRUE)
    
    glue("
Lancet Overall Results:

Data from {k} studies—encompassing {total_int} participants in the intervention group and {total_ctrl} in the control group—yielded a pooled effect size of {effect} (95% CI: {ci_lb} to {ci_ub}). The result was {significance} (p = {signif(p_val, 3)}), supporting the intervention's efficacy.
")
  })
  
  # Plain language overall summary
  output$overall_dynamic_plain <- renderText({
    req(metaResult(), dataInput())
    m.bin <- metaResult()
    dat <- dataInput()
    
    k         <- m.bin$k
    effect    <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb     <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub     <- round(as.numeric(m.bin$upper.random), 2)
    p_val     <- as.numeric(m.bin$pval.random)
    significance <- if(p_val < 0.05) "clearly effective" else "unclear in effectiveness"
    
    total_int <- sum(dat$totalintervention, na.rm = TRUE)
    total_ctrl<- sum(dat$totalcontrol, na.rm = TRUE)
    
    glue("
Plain Language Overall Summary:

We combined results from {k} studies with a total of {total_int} participants receiving the treatment and {total_ctrl} in the control group. The average treatment effect was {effect} (95% CI: {ci_lb} to {ci_ub}), which is considered {significance} (p = {signif(p_val, 3)}).
")
  })
  
  ### 2. HETEROGENEITY RESULTS
  
  output$hetro_dynamic_cochrane <- renderText({
    req(metaResult())
    m.bin <- metaResult()
    
    k       <- m.bin$k
    I2_val  <- as.numeric(m.bin$I2)
    I2      <- round(I2_val, 1)
    Q       <- round(as.numeric(m.bin$Q), 2)
    p_Q     <- signif(as.numeric(m.bin$pval.Q), 3)
    
    heterogeneity_level <- if(I2 < 30) "low" else if(I2 < 60) "moderate" else if(I2 < 75) "substantial" else "considerable"
    effect  <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb   <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub   <- round(as.numeric(m.bin$upper.random), 2)
    
    glue("
Cochrane Heterogeneity Results:

In the meta-analysis of {k} studies, the pooled effect was {effect} (95% CI: {ci_lb} to {ci_ub}). Heterogeneity was {heterogeneity_level} (I² = {I2}%; Q = {Q}, p = {p_Q}). According to Cochrane guidelines, an I² below 30% is considered low, 30–60% moderate, 50–90% substantial, and above 75% considerable.
")
  })
  
  output$hetro_dynamic_nejm <- renderText({
    req(metaResult())
    m.bin <- metaResult()
    
    k       <- m.bin$k
    I2_val  <- as.numeric(m.bin$I2)
    I2      <- round(I2_val, 1)
    Q       <- round(as.numeric(m.bin$Q), 2)
    p_Q     <- signif(as.numeric(m.bin$pval.Q), 3)
    heterogeneity_level <- if(I2 < 30) "low" else if(I2 < 60) "moderate" else if(I2 < 75) "substantial" else "considerable"
    effect  <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb   <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub   <- round(as.numeric(m.bin$upper.random), 2)
    
    glue("
NEJM Heterogeneity Results:

Across {k} studies, the pooled effect was {effect} (95% CI: {ci_lb} to {ci_ub}). The heterogeneity among studies was {heterogeneity_level} (I² = {I2}%; Q = {Q}, p = {p_Q}). This suggests that although there is some variability, the overall result is robust.
")
  })
  
  output$hetro_dynamic_lancet <- renderText({
    req(metaResult())
    m.bin <- metaResult()
    
    k       <- m.bin$k
    I2_val  <- as.numeric(m.bin$I2)
    I2      <- round(I2_val, 1)
    Q       <- round(as.numeric(m.bin$Q), 2)
    p_Q     <- signif(as.numeric(m.bin$pval.Q), 3)
    heterogeneity_level <- if(I2 < 30) "minimal" else if(I2 < 60) "moderate" else if(I2 < 75) "notable" else "considerable"
    effect  <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb   <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub   <- round(as.numeric(m.bin$upper.random), 2)
    
    glue("
Lancet Heterogeneity Summary:

From {k} studies, the pooled effect was {effect} (95% CI: {ci_lb} to {ci_ub}). Heterogeneity was {heterogeneity_level} (I² = {I2}%; Q = {Q}, p = {p_Q}), indicating that while some variability exists, the combined estimate remains reliable.
")
  })
  
  output$hetro_dynamic_plain <- renderText({
    req(metaResult())
    m.bin <- metaResult()
    
    k         <- m.bin$k
    I2_val    <- as.numeric(m.bin$I2)
    I2        <- round(I2_val, 1)
    Q         <- round(as.numeric(m.bin$Q), 2)
    p_Q       <- signif(as.numeric(m.bin$pval.Q), 3)
    heterogeneity_desc <- if(I2 < 30) "little to no" else if(I2 < 60) "moderate" else if(I2 < 75) "quite high" else "very high"
    effect    <- round(as.numeric(m.bin$TE.random), 2)
    ci_lb     <- round(as.numeric(m.bin$lower.random), 2)
    ci_ub     <- round(as.numeric(m.bin$upper.random), 2)
    
    glue("
Plain Language Heterogeneity Summary:

We combined {k} studies and found a pooled effect of {effect} (95% CI: {ci_lb} to {ci_ub}). The variation among the study results is {heterogeneity_desc} (I² = {I2}%, Q = {Q}, p = {p_Q}). This means that the differences between studies are {if(I2 < 30) 'minimal and likely due to chance.' else if(I2 < 60) 'moderate and acceptable.' else if(I2 < 75) 'substantial and worth noting.' else 'very high, which may affect the overall reliability.'}
")
  })
  
  ### 3. META‑REGRESSION RESULTS (Using moderator "Reg")
  
  output$metareg_dynamic_cochrane <- renderText({
    req(dataInput())
    dat <- dataInput()
    if(!("Reg" %in% names(dat))){
      return("Moderator variable 'Reg' not found in the data.")
    }
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      common = (input$effectModel == "FE"),
      random = (input$effectModel == "RE")
    )
    m.reg <- metareg(m.bin, ~ Reg)
    
    coef_reg <- round(as.numeric(m.reg$beta[2]), 2)
    ci_lower <- round(as.numeric(m.reg$ci.lb[2]), 2)
    ci_upper <- round(as.numeric(m.reg$ci.ub[2]), 2)
    p_val    <- round(as.numeric(m.reg$pval[2]), 3)
    significance <- if(p_val < 0.05) "a significant" else "a non-significant"
    
    glue("
Cochrane Meta-Regression Results (Moderator: Reg):

The meta-regression analysis yielded a coefficient of {coef_reg} (95% CI: {ci_lower} to {ci_upper}) for the moderator 'Reg', which is {significance} predictor (p = {p_val}). This indicates that variations in 'Reg' contribute meaningfully to the observed differences across studies.
")
  })
  
  output$metareg_dynamic_nejm <- renderText({
    req(dataInput())
    dat <- dataInput()
    if(!("Reg" %in% names(dat))){
      return("Moderator variable 'Reg' not found in the data.")
    }
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      common = (input$effectModel == "FE"),
      random = (input$effectModel == "RE")
    )
    m.reg <- metareg(m.bin, ~ Reg)
    
    coef_reg <- round(as.numeric(m.reg$beta[2]), 2)
    ci_lower <- round(as.numeric(m.reg$ci.lb[2]), 2)
    ci_upper <- round(as.numeric(m.reg$ci.ub[2]), 2)
    p_val    <- round(as.numeric(m.reg$pval[2]), 3)
    significance <- if(p_val < 0.05) "significantly" else "not significantly"
    
    glue("
NEJM Meta-Regression Results (Moderator: Reg):

The analysis shows that 'Reg' has an estimated coefficient of {coef_reg} (95% CI: {ci_lower} to {ci_upper}), which is {significance} associated with the effect size (p = {p_val}). This supports the idea that 'Reg' is an important factor in explaining between-study differences.
")
  })
  
  output$metareg_dynamic_lancet <- renderText({
    req(dataInput())
    dat <- dataInput()
    if(!("Reg" %in% names(dat))){
      return("Moderator variable 'Reg' not found in the data.")
    }
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      common = (input$effectModel == "FE"),
      random = (input$effectModel == "RE")
    )
    m.reg <- metareg(m.bin, ~ Reg)
    
    coef_reg <- round(as.numeric(m.reg$beta[2]), 2)
    ci_lower <- round(as.numeric(m.reg$ci.lb[2]), 2)
    ci_upper <- round(as.numeric(m.reg$ci.ub[2]), 2)
    p_val    <- round(as.numeric(m.reg$pval[2]), 3)
    significance <- if(p_val < 0.05) "significant" else "non-significant"
    
    glue("
Lancet Meta-Regression Results (Moderator: Reg):

The estimated coefficient for 'Reg' was {coef_reg} (95% CI: {ci_lower} to {ci_upper}), which was {significance} (p = {p_val}). This finding suggests that 'Reg' is an important contributor to the variability observed among the study outcomes.
")
  })
  
  output$metareg_dynamic_plain <- renderText({
    req(dataInput())
    dat <- dataInput()
    if(!("Reg" %in% names(dat))){
      return("Moderator variable 'Reg' not found in the data.")
    }
    m.bin <- metacont(
      n.e = dat$totalintervention,
      mean.e = dat$meanintervention,
      sd.e = dat$sdintervention,
      n.c = dat$totalcontrol,
      mean.c = dat$meancontrol,
      sd.c = dat$sdcontrol,
      studlab = dat$author,
      data = dat,
      sm = input$effectMeasure,
      method.smd = input$method.smd,
      method.tau = input$method.tau,
      common = (input$effectModel == "FE"),
      random = (input$effectModel == "RE")
    )
    m.reg <- metareg(m.bin, ~ Reg)
    
    coef_reg <- round(as.numeric(m.reg$beta[2]), 2)
    ci_lower <- round(as.numeric(m.reg$ci.lb[2]), 2)
    ci_upper <- round(as.numeric(m.reg$ci.ub[2]), 2)
    p_val    <- round(as.numeric(m.reg$pval[2]), 3)
    significance <- if(p_val < 0.05) "clearly affects" else "does not appear to affect"
    
    glue("
Plain Language Meta-Regression Summary (Moderator: Reg):

For the moderator 'Reg', the estimated effect is {coef_reg} (with a 95% confidence interval from {ci_lower} to {ci_upper}). This result suggests that differences in 'Reg' {significance} the overall outcome (p = {p_val}).
")
  })
  
  # (You can add additional dynamic text sections for other outcomes similarly.)
  
  output$funnelPlot <- renderPlot({
    req(dataInput())
    dat <- dataInput()
    
    # Convert the data for meta-analysis
    m.bin <- metacont(n.e = dat$totalintervention,
                      mean.e = dat$meanintervention,
                      sd.e = dat$sdintervention,
                      n.c = dat$totalcontrol,
                      mean.c = dat$meancontrol,
                      sd.c = dat$sdcontrol,
                      studlab = dat$author,
                      data = dat,
                      sm = input$effectMeasure,
                      method.smd = input$method.smd,
                      method.tau = input$method.tau,
                      comb.fixed = input$effectModel == "FE",
                      comb.random = input$effectModel == "RE")
    
    print(summary(m.bin))
    
    # Define fill colors for contour
    col.contour <- c("gray75", "gray85", "gray95")
    
    if (input$colorFunnel) {
      # Color-enhanced funnel plot with slider-based x-axis limits
      funnel(m.bin, xlim = input$funnelXRange, contour = c(0.9, 0.95, 0.99), col.contour = col.contour)
      legend("topright", inset = 0.05,
             legend = c("p < 0.1", "p < 0.05", "p < 0.01"),
             fill = col.contour)
      title(main = "Contour-Enhanced Funnel Plot")
    } else {
      # Standard funnel plot with slider-based x-axis limits
      funnel(m.bin, xlim = input$funnelXRange)
    }
  })
}
shinyApp(ui = ui, server = server)


# Run the application


